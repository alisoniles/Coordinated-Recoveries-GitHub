---
title: "3_EDM_CCM_pairwise_causality_multispatial"
author: "Alison Iles"
date: "10/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rEDM)
library(multispatialCCM)
library(tidyr)
library(stringr)

library(ggplot2)
library(ggforce)
library(gridExtra)
library(tictoc)
```


#run multispatial convergent cross-mapping algorithm on two time series, A and B, to determine whether process A is a forcing process for process B. 

prints convergence plots for every tau of every offset


#load the data and functions
```{R}
rm(list=ls()) 

#data <- D_MFS[,c("year", An, Bn)]; min_stock_size = (E_A_MFS*(T_A_MFS-1)+T_A_MFS)
#Function to remove to extra NAs, but leave one NA between each stock's data in an MPG
#'data' with columns, year, focal variable and any putative causal variable
shape_block_data <- function(data, min_stock_size = 30) {
  
         data <- rbind(c(NA,NA,NA),data) #add an initial row of NA so the difference function works for the first row
         
         dataNA <- (is.na(data[,3]) | is.na(data[,2])) # if there is no data for the causal variable, remove the Chinook data too at this point.
         data[dataNA,1:3] <- NA
         rownames(data) <- NULL
  
         #record the beginning and endpoints of each data chunk
         CC <- complete.cases(data[,2])  
         lib <- matrix(NA, nrow = length(which(diff(CC)==1)), ncol = 2)
                lib[,1] <- which(diff(CC)==1)+1
                lib[,2] <- which(diff(CC)==-1)
         
         #only include in the library the sections of data that are continuous for at least 20 time points. 
         minlib <- lib[,2]-lib[,1]+1
         lib <- lib[minlib>min_stock_size,] 
         #if there are no library chunks long enough, then return error
         if(nrow(lib)==0){
           print("Error - data chunks are too small for the given E and tau")
           return()
         }
         
         x <- c(NA, NA, NA)
             for (r in 1:nrow(lib)){
                 xtmp <- data[lib[r,1]:lib[r,2],]
                 x <- rbind(x,c(NA, NA, NA),xtmp)}
         data <- (x[3:nrow(x),])
         data <- as.data.frame(data)
         rownames(data) <- NULL
         
         data <- as.matrix(data)
         data <- cbind(as.numeric(data[,1]), as.numeric(data[,2]), as.numeric(data[,3]))
         colnames(data) <- c("year", "rec", "PCV")
         return(data)
}

#modified ccmtest function to test one-way interactions (we're only interested in the effects on salmon, not what salmon affect and most of the variables are exogenous anyway)

ccmtest_oneway <- function(CCM_boot_AcB) {
    #Tests for significant causal signal based on 95%
    #confidence intervals from bootstrapping.
    #Compares shortest library to longest
    pval_a_cause_b<-1-sum(CCM_boot_AcB$FULLinfo[1,]<
      CCM_boot_AcB$FULLinfo[nrow(CCM_boot_AcB$FULLinfo),], na.rm=T)/
      ncol(CCM_boot_AcB$FULLinfo)
    return(pval_a_cause_b)
  }


#Run the multispatial convergent cross mapping algorithm on A causing B and B causing A. 
# This function runs the multispatial CCM_boot and tests output from CCM_boot for significant causal signal using ccmtest to compare the 95% confidence intervals for estimated rho for the shortest and longest libraries calculated, and uses this to determine whether predictive power has significantly increased.  Reorganizes the output into a data frame for plotting. 
# Desired library lengths for which to compute CCM. Defaults to the maximum possible length ((tau * (E - 1) + (E + 1)):length(A) - E + 2) (though number of resulting predictions may be smaller because of gaps in the time series). Shortening this list (e.g., only predicting every nth element) will reduce run-time for the algorithm, but may also reduce ability to detect causal relations.
#A <- AB[,2]; B <- AB[,3]; An <- An; Bn <- Bn; EB <- EB; tau <- tau
CCM_boot_df_and_sig_test <- function(A, B, An, Bn, EB, tau)
    {
          
          DL <- ((tau * (EB - 1) + (EB + 1)):length(A) - EB + 2)
          DL <- DL[seq(1, length(DL), max(c(floor(length(DL)/100), 1)))] #reduced the desired library lengths to only 100. This speeds up the algorithm but may also reduce the ability to detect causal relations. 
          
          CCM_BcA <- CCM_boot(B, A, EB, tau=tau, DesiredL=DL, iterations=500) # Does B "cause" A?
          CCM_A_B_sig_test<-ccmtest_oneway(CCM_BcA)

          #make data frame of results for output
          BcA_df <- as.data.frame(cbind(CCM_BcA$Lobs, CCM_BcA$rho, CCM_BcA$sdevrho, (CCM_BcA$rho-CCM_BcA$sdevrho), (CCM_BcA$rho+CCM_BcA$sdevrho)))
          colnames(BcA_df) <- c("Lobs", "rho", "sdevrho", "lower", "upper")
          
          BcA_df$model <- paste(Bn, " causes ", An, ", p = ", signif(CCM_A_B_sig_test,2) , sep="")
          BcA_df$response_var <- An
          BcA_df$causal_var <- Bn
          BcA_df$pval <- signif(CCM_A_B_sig_test,2)
          BcA_df$E <- EB
          BcA_df$tau <- tau
          
          #estimate slope of rho values as a function of library size for the largest 1/4 of library sizes
          D <- BcA_df[BcA_df$Lobs > (max(BcA_df$Lobs, na.rm=TRUE)*0.75),]
          BcA_df$slope <- lm(D$rho ~D$Lobs)$coefficients[2]
           
          return(BcA_df)
    }



#create list of beginning and end points for chunks of time series combined in the same embedding. Year must be in the first column of the time series. Complete cases only. Removes sections that are not continuous for at least 18 time points. Returns lib and the narrowed data block. 
    create_lib <- function(d, cont_tp)
{
         lib <- matrix(NA, nrow = length(which(diff(d[,1])!=1))+1, ncol = 2) 
             lib[,1] <- c(1, which(diff(d[,1])!=1)+1)
             lib[,2] <- c(which(diff(d[,1])!=1), nrow(d))
        
         minlib <- lib[,2]-lib[,1] #only include in the library the sections of data that are continuous for at least 'cont_tp' time points. 
         lib <- lib[minlib>=cont_tp,] 
             
    return(lib)
    }

```


```{R}
#shape causal variable list, output data frame and input data frames for the CCM functions

load("Data/Rdata/block_data.Rdata")  
      aa <- t(data.frame(as.list(names(block_data[[1]]))))
          rownames(aa) <- NULL #remove rownames
      bb <- data.frame(c(aa[31:nrow(aa)] ))
          colnames(bb) <- c("variable")
      cc <- str_split_fixed(bb$variable, "[.]",n=3)
      var_list <- cbind(bb,cc)
      
      var_list[,5:21] <- matrix(NA, nrow = NROW(var_list), ncol = 17)
      
      
      colnames(var_list) <- c("target", "cat", "subcat", "offset", "E",
                              "ESU rho","ESU sd", "ESU pval", "ESU slope", 
                              "MFS rho","MFS sd", "MFS pval", "MFS slope", 
                              "IMN rho","IMN sd", "IMN pval", "IMN slope",
                              "UPS rho","UPS sd", "UPS pval", "UPS slope")     
      var_list$offset <- as.numeric(var_list$offset)
      rm("aa", "bb", "cc")
      
      vars <- c("stk", "year", "salm.rec4n.0", "salm.rec5n.0", "salm.recspn4n.0", "salm.recspn5n.0", var_list$target) 

#concatenate the stock time series together for each MPG and ESU to create input data frames for the CCM functions
D_ESU <- as.matrix(rbind(block_data$'Bear Valley Creek'[vars], NA,  
              block_data$'Big Creek'[vars], NA,  
              block_data$'Camas Creek'[vars], NA,  
              block_data$'Catherine Creek'[vars], NA,  
              block_data$'Chamberlain Creek'[vars], NA,  
              block_data$'East Fork Salmon River'[vars], NA,  
              block_data$'East Fork South Fork'[vars], NA,  
              block_data$'Grande Ronde Upper Mainstem'[vars], NA,  
              block_data$'Imnaha River'[vars], NA,  
              block_data$'Lemhi River'[vars], NA,  
              block_data$'Loon Creek'[vars], NA,  
              block_data$'Lostine River'[vars], NA,  
              block_data$'Marsh Creek'[vars], NA,  
              block_data$'Middle Fork Salmon River above Indian Creek'[vars], NA,  
              block_data$'Middle Fork Salmon River below Indian Creek'[vars], NA,  
              block_data$'Minam River'[vars], NA,  
              block_data$'North Fork Salmon River'[vars], NA,  
              block_data$'Pahsimeroi River'[vars], NA,  
              block_data$'Salmon River Lower Mainstem below Redfish Lake'[vars], NA,  
              block_data$'Salmon River Upper Mainstem above Redfish Lake'[vars], NA,  
              block_data$'Secesh River'[vars], NA,  
              block_data$'South Fork Salmon River Mainstem'[vars], NA,  
              block_data$'Sulphur Creek'[vars], NA,  
              block_data$'Tucannon River'[vars], NA,  
              block_data$'Valley Creek'[vars], NA,  
              block_data$'Wallowa River, Hurricane Creek, Bear Creek, and Lostine Rivers'[vars], NA,  
              block_data$'Wenaha River'[vars], NA,  
              block_data$'Yankee Fork'[vars]))

D_MFS <- as.matrix(rbind(block_data$'Bear Valley Creek'[vars], NA, 
           block_data$'Big Creek'[vars], NA, 
           block_data$'Camas Creek'[vars], NA, 
           block_data$'Chamberlain Creek'[vars], NA, 
           block_data$'Loon Creek'[vars], NA, 
           block_data$'Marsh Creek'[vars], NA, 
           block_data$'Middle Fork Salmon River above Indian Creek'[vars], NA, 
           block_data$'Middle Fork Salmon River above Indian Creek'[vars], NA, 
           block_data$'Sulphur Creek'[vars]))

D_IMN <- as.matrix(rbind(block_data$'Catherine Creek'[vars], NA, 
                     block_data$'Grande Ronde Upper Mainstem'[vars], NA, 
                     block_data$'Imnaha River'[vars], NA, 
                     block_data$'Lostine River'[vars], NA, 
                     block_data$'Minam River'[vars], NA, 
                     block_data$'Wallowa River, Hurricane Creek, Bear Creek, and Lostine Rivers'[vars], NA, 
                     block_data$'Wenaha River'[vars], NA))
  
D_UPS <- as.matrix(rbind(block_data$'East Fork Salmon River'[vars], NA, 
                     block_data$'Lemhi River'[vars], NA, 
                     block_data$'North Fork Salmon River'[vars], NA, 
                     block_data$'Pahsimeroi River'[vars], NA, 
                     block_data$'Salmon River Lower Mainstem below Redfish Lake'[vars], NA, 
                     block_data$'Salmon River Upper Mainstem above Redfish Lake'[vars], NA, 
                     block_data$'Valley Creek'[vars], NA, 
                     block_data$'Yankee Fork'[vars], NA))


```
#the minimum library length for the CCM_boot function depends on E and tau. The maximum library length depends on the length of the data - (E+2)
x <- cbind((Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1))*rbind(c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7),c(1:7))
minL =  x + cbind((Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1),(Emat[,1]-1))
maxL = 

#Loop through all the lags of each putative causal variable and test for causality for the four main time series
```{R}
      
#Choose the focal variable to run the analysis for
An <- "salm.recspn5n.0"  # "salm.rec4n", "salm.rec5n", "salm.recspn4n", "salm.recspn5n"
An_short <- "recspn5" 
load(file = paste("Output/Rdata/3_CCM/3_multispatial_CCM_results_", An_short, ".Rdata", sep=""))

        #Get the optimal E and tau for the focal variables from the output table from '2_EDM_Nonlinearity_CORE.Rmd'
        E_T <- readRDS(file = "Output/Rdata/2_Nonlinearity/Diagnostic_results.RDS")
        #change some of the values for tau and E based on the diagnostic plots    
   
            E_T[3,3] <- 4; E_T[3,4] <- 8 #recspn4 at ESU level
            E_T[7,3] <- 4; E_T[7,4] <- 8 #recspn4 for MFS
            E_T[11,3] <- 4; E_T[11,4] <- 8 #recspn4 for IMN
            E_T[15,3] <- 4; E_T[15,4] <- 8 #recspn4 for UPS
            E_T[5,3] <- 2; E_T[5,3] <- 7 #recspn5 at ESU level 
            E_T[8,3] <- 2; E_T[8,4] <- 7 #recspn5 for MFS
            E_T[12,3] <- 2; E_T[12,4] <- 7 #recspn5 for IMN
            E_T[16,3] <- 2; E_T[16,4] <- 7 #recspn5 for UPS
             
            E_A_ESU <- as.numeric(E_T[(E_T[,1]=="ESU" & E_T[,2]==An),4])
            E_A_MFS <- as.numeric(E_T[(E_T[,1]=="MFS" & E_T[,2]==An),4])
            E_A_IMN <- as.numeric(E_T[(E_T[,1]=="IMN" & E_T[,2]==An),4])
            E_A_UPS <- as.numeric(E_T[(E_T[,1]=="UPS" & E_T[,2]==An),4])
            T_A_ESU <- as.numeric(E_T[(E_T[,1]=="ESU" & E_T[,2]==An),3])
            T_A_MFS <- as.numeric(E_T[(E_T[,1]=="MFS" & E_T[,2]==An),3])
            T_A_IMN <- as.numeric(E_T[(E_T[,1]=="IMN" & E_T[,2]==An),3])
            T_A_UPS <- as.numeric(E_T[(E_T[,1]=="UPS" & E_T[,2]==An),3])
            

c <- 7; s <- 7; i <- 1
CCM_summary <- matrix(data=NA, nrow=1, ncol=7); colnames(CCM_summary) <- c("model", "response_var", "causal_var", "pval", "E", "tau", "slope")      

unique_cat <- unique(var_list$cat) #for each unique putative causal variable category
for (c in 11:length(unique_cat)){
cat_name <- unique_cat[c]    
var_list_cat <- var_list[var_list$cat==cat_name,]

unique_subcat <- unique(var_list_cat$subcat)
for (s in 3:length(unique_subcat)){  #for each unique subcategory of the causal variable category 
    var_list_subcat <- var_list_cat[var_list_cat$subcat==unique_subcat[s],]

subplot_list = list()
for(i in nrow(var_list_subcat):1){  #for each offset of the causal variable subcategory
Bn <- var_list_subcat[i,1]
v <- which(var_list$target == Bn) #for indexing the results table

tic()
#find optimal E for putative causal variable
        D <- as.matrix(block_data$'Wenaha River'[c("year", Bn)])
        maxE<-floor(sqrt(sum(complete.cases(D)))) #Maximum E to test: E ≤ sqrt(n)
        Emat<-matrix(nrow=maxE-1, ncol=2); colnames(Emat)<-c("E", "Bn") #Matrix for storing output
            #Loop over potential E values and calculate predictive ability of each process for its own dynamics
            for(E in 2:maxE) {
              #Uses defaults of looking forward one prediction step (predstep)
              #And using time lag intervals of one time step (tau)
              Emat[E-1,"E"] <- E
              Emat[E-1,"Bn"]<-SSR_pred_boot(A=D, E=E, predstep=1, tau=1)$rho
            }
        #We defined E as the smallest dimension that came within 1% of the best predictive value observed across all dimensions with E ≤ sqrt(n), where
        #n is time series length (Sugihara & May 1990; Sugihara et al. 2012; Ye et al. 2015; Karacoc et at 2020). 
        maxrho=max(Emat[,"Bn"], na.rm=TRUE)
            EB <- min(Emat[(Emat[,"Bn"]>=(maxrho-(maxrho*0.01))),"E"], na.rm=TRUE)
            var_list$E[v] <- EB

            

#run the multispatial CCM and record results
AB <- shape_block_data(D_ESU[,c("year", An, Bn)], min_stock_size = 10)
for(tau in 1:6){
          CCM <- CCM_boot_df_and_sig_test(A=AB[,2], B=AB[,3], An=An, Bn=Bn, EB=EB, tau=tau)
          if(tau==1){ CCM_all_tau <-CCM }
          if(tau>1){ CCM_all_tau <- rbind(CCM_all_tau, CCM) }
          CCM_summary <- rbind(CCM_summary, CCM[1,6:12])
}
          CCM_all_tau$tau <- as.character(CCM_all_tau$tau)
          maxrho <- max(CCM_all_tau$upper)
          pESU <- ggplot(CCM_all_tau, aes(x=Lobs, y=rho, ymin=lower, ymax=upper, color=tau, fill=tau)) +
               geom_line() +
               geom_ribbon(alpha=0.2, linetype = 0) + 
               ylim(NA, (0.2+maxrho)) +
               labs(x = "Library length, L", title = paste("ESU, offset: ", var_list$offset[v], sep="")) +
               geom_hline(aes(yintercept=0), colour='#999999') +
               theme_bw() + 
               theme( legend.position = c(.01, .99), legend.justification = c("left", "top"), legend.box.just = "left",
                      legend.margin=margin(0,0,0,0), legend.title = element_blank(), legend.text = element_text(size = 8), legend.background = element_blank()) +
               scale_fill_discrete(
                      breaks=c("1", "2", "3", "4", "5", "6", "7"),
                      labels=c(paste("Tau =", c("1", "2", "3", "4", "5", "6", "7"), ", p =", CCM_summary$pval[(nrow(CCM_summary)-5):nrow(CCM_summary)]))) +
               scale_color_discrete(
                      breaks=c("1", "2", "3", "4", "5", "6", "7"),
                      labels=c(paste("Tau =", c("1", "2", "3", "4", "5", "6", "7"), ", p =", CCM_summary$pval[(nrow(CCM_summary)-5):nrow(CCM_summary)])))
          subplot_list[[(1+((i-1)*4))]] = pESU


AB <- shape_block_data(D_MFS[,c("year", An, Bn)], min_stock_size = 10)     
if(is.null(AB)==FALSE){for(tau in 1:6){
          CCM <- CCM_boot_df_and_sig_test(A=AB[,2], B=AB[,3], An=An, Bn=Bn, EB=EB, tau=tau)
          if(tau==1){ CCM_all_tau <-CCM }
          if(tau>1){ CCM_all_tau <- rbind(CCM_all_tau, CCM) }
          CCM_summary <- rbind(CCM_summary, CCM[1,6:12])
}
          CCM_all_tau$tau <- as.character(CCM_all_tau$tau)
          maxrho <- max(CCM_all_tau$upper)
          pMFS <- ggplot(CCM_all_tau, aes(x=Lobs, y=rho, ymin=lower, ymax=upper, color=tau, fill=tau)) +
               geom_line() +
               geom_ribbon(alpha=0.2, linetype = 0) + 
               ylim(NA, (0.2+maxrho)) +
               labs(x = "Library length, L", title = paste("MFS, offset: ", var_list$offset[v], sep="")) +
               geom_hline(aes(yintercept=0), colour='#999999') +
               theme_bw() + 
               theme( legend.position = c(.01, .99), legend.justification = c("left", "top"), legend.box.just = "left",
                      legend.margin=margin(0,0,0,0), legend.title = element_blank(), legend.text = element_text(size = 8), legend.background = element_blank()) +
               scale_fill_discrete(
                      breaks=c("1", "2", "3", "4", "5", "6", "7"),
                      labels=c(paste("Tau =", c("1", "2", "3", "4", "5", "6", "7"), ", p =", CCM_summary$pval[(nrow(CCM_summary)-5):nrow(CCM_summary)]))) +
               scale_color_discrete(
                      breaks=c("1", "2", "3", "4", "5", "6", "7"),
                      labels=c(paste("Tau =", c("1", "2", "3", "4", "5", "6", "7"), ", p =", CCM_summary$pval[(nrow(CCM_summary)-5):nrow(CCM_summary)])))

          subplot_list[[(2+((i-1)*4))]] = pMFS
}          


AB <- shape_block_data(D_IMN[,c("year", An, Bn)], min_stock_size = 10)
for(tau in 1:6){
          CCM <- CCM_boot_df_and_sig_test(A=AB[,2], B=AB[,3], An=An, Bn=Bn, EB=EB, tau=tau)
          if(tau==1){ CCM_all_tau <-CCM }
          if(tau>1){ CCM_all_tau <- rbind(CCM_all_tau, CCM) }
          CCM_summary <- rbind(CCM_summary, CCM[1,6:12])
}
          CCM_all_tau$tau <- as.character(CCM_all_tau$tau)
          maxrho <- max(CCM_all_tau$upper)
          pIMN <- ggplot(CCM_all_tau, aes(x=Lobs, y=rho, ymin=lower, ymax=upper, color=tau, fill=tau)) +
               geom_line() +
               geom_ribbon(alpha=0.2, linetype = 0) + 
               ylim(NA, (0.2+maxrho)) +
               labs(x = "Library length, L", title = paste("IMN, offset: ", var_list$offset[v], sep="")) +
               geom_hline(aes(yintercept=0), colour='#999999') +
               theme_bw() + 
               theme( legend.position = c(.01, .99), legend.justification = c("left", "top"), legend.box.just = "left",
                      legend.margin=margin(0,0,0,0), legend.title = element_blank(), legend.text = element_text(size = 8), legend.background = element_blank()) +
               scale_fill_discrete(
                      breaks=c("1", "2", "3", "4", "5", "6", "7"),
                      labels=c(paste("Tau =", c("1", "2", "3", "4", "5", "6", "7"), ", p =", CCM_summary$pval[(nrow(CCM_summary)-5):nrow(CCM_summary)]))) +
               scale_color_discrete(
                      breaks=c("1", "2", "3", "4", "5", "6", "7"),
                      labels=c(paste("Tau =", c("1", "2", "3", "4", "5", "6", "7"), ", p =", CCM_summary$pval[(nrow(CCM_summary)-5):nrow(CCM_summary)])))
          subplot_list[[(3+((i-1)*4))]] = pIMN


AB <- shape_block_data(D_UPS[,c("year", An, Bn)], min_stock_size = 10)
for(tau in 1:6){
          CCM <- CCM_boot_df_and_sig_test(A=AB[,2], B=AB[,3], An=An, Bn=Bn, EB=EB, tau=tau)
          if(tau==1){ CCM_all_tau <-CCM }
          if(tau>1){ CCM_all_tau <- rbind(CCM_all_tau, CCM) }
          CCM_summary <- rbind(CCM_summary, CCM[1,6:12])
}
          CCM_all_tau$tau <- as.character(CCM_all_tau$tau)
          maxrho <- max(CCM_all_tau$upper)
          pUPS <- ggplot(CCM_all_tau, aes(x=Lobs, y=rho, ymin=lower, ymax=upper, color=tau, fill=tau)) +
               geom_line() +
               geom_ribbon(alpha=0.2, linetype = 0) + 
               ylim(NA, (0.2+maxrho)) +
               labs(x = "Library length, L", title = paste("UPS, offset: ", var_list$offset[v], sep="")) +
               geom_hline(aes(yintercept=0), colour='#999999') +
               theme_bw() + 
               theme( legend.position = c(.01, .99), legend.justification = c("left", "top"), legend.box.just = "left",
                      legend.margin=margin(0,0,0,0), legend.title = element_blank(), legend.text = element_text(size = 8), legend.background = element_blank()) +
               scale_fill_discrete(
                      breaks=c("1", "2", "3", "4", "5", "6", "7"),
                      labels=c(paste("Tau =", c("1", "2", "3", "4", "5", "6", "7"), ", p =", CCM_summary$pval[(nrow(CCM_summary)-5):nrow(CCM_summary)]))) +
               scale_color_discrete(
                      breaks=c("1", "2", "3", "4", "5", "6", "7"),
                      labels=c(paste("Tau =", c("1", "2", "3", "4", "5", "6", "7"), ", p =", CCM_summary$pval[(nrow(CCM_summary)-5):nrow(CCM_summary)])))
          subplot_list[[(4+((i-1)*4))]] = pUPS


print(Bn)          
toc()         
}


     n <- length(subplot_list)
     nCol <- 4 #floor(sqrt(n))
     
     pCCM <- do.call("grid.arrange", c(subplot_list[1:20], ncol=nCol, left=paste("forecast skill, ", expression(rho), sep=""), top=paste("Multispatial CCM test:\n", cat_name, unique_subcat[s], "as a forcing process on", An_short, sep=" "), bottom="library length, L"))
     
     

ggsave(filename = paste("Output/Figures/3_CCM/Multispatial/", cat_name, "_", unique_subcat[s],"_CCM_", An_short, ".pdf", sep = ""), plot = pCCM, width = 12, height = 12, units = "in")  # saves the last plot

               
}
}

CCM_out <- CCM_summary
save(CCM_out, file = paste("Output/Rdata/3_CCM/3_multispatial_CCM_results_", An_short, ".Rdata", sep=""))


```





               }


```{R}



      
data_ESU <- rbind(block_data$'Bear Valley Creek', 
              block_data$'Big Creek', 
              block_data$'Camas Creek', 
              block_data$'Catherine Creek', 
              block_data$'Chamberlain Creek', 
              block_data$'East Fork Salmon River', 
              block_data$'East Fork South Fork', 
              block_data$'Grande Ronde Upper Mainstem', 
              block_data$'Imnaha River', 
              block_data$'Lemhi River', 
              block_data$'Loon Creek', 
              block_data$'Lostine Creek', 
              block_data$'Marsh Creek', 
              block_data$'Middle Fork Salmon River above Indian Creek', 
              block_data$'Middle Fork Salmon River below Indian Creek', 
              block_data$'Minam River', 
              block_data$'North Fork Salmon River', 
              block_data$'Pahsimeroi River', 
              block_data$'Salmon River Lower Mainstem below Redfish Lake', 
              block_data$'Salmon River Upper Mainstem above Redfish Lake', 
              block_data$'Secesh River', 
              block_data$'South Fork Salmon River Mainstem', 
              block_data$'Sulphur Creek', 
              block_data$'Tucannon River', 
              block_data$'Valley Creek', 
              block_data$'Wallowa River, Hurricane Creek, Bear Creek, and Lostine Rivers', 
              block_data$'Wenaha River', 
              block_data$'Yankee Fork')   

data_MFS <- data_ESU[data_ESU$mpg=="Middle Fork Salmon",]
data_IMN <- data_ESU[data_ESU$mpg=="Imnaha",]
data_UPS <- data_ESU[data_ESU$mpg=="Upper Salmon",]

#use optimal base embeddings for each target variable, rec4 and rec 5
if(tarvar=="salm.rec4n.0") {vars <-  c("year", tarvar,"salm.effn.0", "salm.rec5n.0", var_names[,1])
                            nvars <- 4}  #effn and rec5s from the same cohort
if(tarvar=="salm.rec5n.0") {vars <-  c("year", tarvar,"salm.effn.0", "salm.rec4n.1", "salm.rec3n.2", var_names[,1])
                            nvars <- 5} #effn, rec3s and rec4s from the same return year

level=c("ESU", "MiddleForkSalmon", "Imnaha", "UpperSalmon")
for(l in (1:4)){  #loop through the ESU and the different MPGs
  if(l==1){MVE_block <- as.data.frame(data_ESU[vars])}
  if(l==2){MVE_block <- as.data.frame(data_MFS[vars])}
  if(l==3){MVE_block <- as.data.frame(data_IMN[vars])}
  if(l==4){MVE_block <- as.data.frame(data_UPS[vars])}
  
  base_d  <- MVE_block[,c(1:nvars)] #The first few time series selected in 'vars' above form the base embedding 

 # Run multivariate CCM with block_lnlp function on each putative causal variable
for (s in (1:NROW(var_names))){  
               varname <- var_names$var[s]
               d <- cbind(base_d,MVE_block[,varname])
               colnames(d) <- c(colnames(base_d), varname)
               
               #create library for data block d that excludes rows with NA and includes only sections continuous for at least 18 time points
               d <- d[complete.cases(d), ] #remove rows with NA
               lib <- create_lib(d, 18) #create library for data block d that includes only sections continuous for at least 18 time points
               if (nrow(lib)==0) {
               next
               }
                   x <- d[lib[1,1]:lib[1,2],] #narrow the data block to these library sections
                          for (r in 2:nrow(lib)){
                              xtmp <- d[lib[r,1]:lib[r,2],]
                              x <- rbind(x,xtmp)
                          }
                    d <- x
              lib <- create_lib(d, 18) #recreate the library list
              
              ccm <- block_lnlp(d, lib = lib, 
                                 columns = 1:(NCOL(d)-1), 
                                 target_column = varname, 
                                 method = 'simplex', 
                                 tp = 1, 
                                 first_column_time = TRUE, 
                                 silent = TRUE)
             
             CCM_out$ccm_rho[s] <- ccm$rho
             CCM_out$N[s] <- ccm$num_pred
             CCM_out$`95p_crit_rho`[s] <- qnorm(0.95, sd = 1/sqrt(ccm$num_pred - 3)) #qnorm is used to look up percentiles of the standard normal distribution. The 0.95 quantile is the 95th percentile. qnorm produces the boundary value that the rho needs to be greater than in order to be signifcantly different from zero and p=0.05 level. 
             CCM_out$Nrow_lib[s] <- nrow(lib)
              
             #Basic convergence test: calculate the mean rho from thr minimum library size and use Fisher's Z to test that the max library z is significantly higher than the begining. Transforms the rho at the min library and max library length to a normally distributed Fisher's z value Independent correlations, different sample sizes. 
                        min_rho <- matrix(NA, nrow = NROW(lib), ncol = 1)
                        for(i in 1:nrow(lib)){
                         min_rho_ccm <- block_lnlp(d, lib = lib[i,], pred = lib,
                                           columns = 1:(NCOL(d)-1), 
                                           target_column = varname, 
                                           method = 'simplex', 
                                           tp = 1, 
                                           first_column_time = TRUE, 
                                           silent = TRUE)
                        min_rho[i] <- min_rho_ccm$rho
                        }
            minlibsize <- median(lib[,2]-lib[,1])
            maxlibsize <- nrow(d) - minlibsize
            FZ <- paired.r(mean(min_rho), ccm$rho, NULL, minlibsize, maxlibsize, twotailed=FALSE)
            CCM_out$FisherZ[s] <- FZ$p              
              


          }

saveRDS(CCM_out, file = paste("Output/Rdata/3_CCM/3_CCM_optimal_base_",level[l],"_",tarvarshort,".RDS", sep = ""), compress = FALSE)

}  
```
  