---
title: "EDM_Chinook"
author: "Alison Iles"
date: "12/5/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Load package and time series
All the EDM analyses are carried out by the rEDM package.

```{r}
# loading R packages
library(rEDM)
library(Kendall)

folder <- "/Users/alisoniles/Google Drive/Coordinated Recoveries/Data/analysis ready/"      # path to folder that holds multiple .csv files
file_list <- list.files(path=folder, pattern="*.csv") # create list of all .csv files in folder

# read in each .csv file in file_list and create a data frame with the same name as the .csv file
for (i in 1:length(file_list)){
  assign(file_list[i], 
  read.csv(paste(folder, file_list[i], sep=''))
)}

## To put all ready to analyze data:
dat <- NULL

# Data normalization: Prior to simplex projection, the time series are normalized to zero mean and unit variance.
D <- (IHR_Fall_Chinook.csv$adult+IHR_Fall_Chinook.csv$jack) #Add adults and jacks together?
dat$FChnk <- ((D-mean(D))/sd(D)) 

D <- (IHR_SprSum_Chinook.csv$adult+IHR_SprSum_Chinook.csv$jack) #Add adults and jacks together?
dat$SChnk <- ((D-mean(D))/sd(D)) 

PDO.csv$PDOya <- ((PDO.csv[,"PDOya"]-mean(PDO.csv[,"PDOya"]))/sd(PDO.csv[,"PDOya"]))
plot(PDO.csv$PDOya~PDO.csv$Year,type="l",xlab="Year",ylab="PDO",ylim=c(-2,2),col=2,main="PDO time series")

SRKW.csv$SR_Orca <- ((SRKW.csv[,"SR_Orca"]-mean(SRKW.csv[,"SR_Orca"]))/sd(SRKW.csv[,"SR_Orca"]))

sealion.csv$Pup.count <- ((sealion.csv[,"Pup.count"]-mean(sealion.csv[,"Pup.count"]))/sd(sealion.csv[,"Pup.count"]))
sealion.csv$Male <- ((sealion.csv[,"Male"]-mean(sealion.csv[,"Male"]))/sd(sealion.csv[,"Male"]))
```
Simplex projection (Sugihara & May 1990)

The complexity of a system can be practically defined as the number of independent variables needed to reconstruct the attractor (i.e. dimensionality of the system). Determining the best embedding dimension E with 'Simplex projection' is a fundamental first step in all EDM analysis. 

By simplex projection, we make one-step, out-of-sample forward forecast (predict t+1 step) using different values of E to determine the optimal embedding dimension. We present the results showing the relationship between the predictive skill (ρ - the correlation coefficient between observations and forecasts) and the embedding dimension (E) (Fig. 2c & d in the main text).

Note that, in the case where the time series is rather short, leave-one-out cross-validation can be performed instead of dividing the time series into halves (Sugihara et al. 1996; Glaser et al. 2014).
```{r}
# The simplex projection is carried out by the function rEDM::simplex(). 
# We divide the time series into two halves. The first half is used as the library set for manifold reconstruction. The second half is used as the target for out-of-sample prediction. 
# The argument lib is the time index indicating the start (1) and the end (n/2) in the library set, respectively. Similarly, the argument pred indicates the time index in the prediction set. 
n <- round(length(dat$FChnk)/2)
# We specify a sequence of testing embedding dimensions from 2 to 8 by the argument E=c(2:8), which executes the simplex projections using different embedding dimensions.
sim_FChnk <- simplex(dat$FChnk,lib=c(1,n),pred=c(n+1,length(dat$FChnk)),E=c(2:10)) #Fall Chinook
sim_SChnk <- simplex(dat$SChnk,lib=c(1,n),pred=c(n+1,length(dat$SChnk)),E=c(2:10)) # Spring/Summer Chinook
sim_PDO <- simplex(PDO.csv$PDOya,lib=c(1,round(length(PDO.csv$PDOya)/2)),pred=c(round(length(PDO.csv$PDOya)/2)+1,length(PDO.csv$PDOya)),E=c(2:10)) # PDO
sim_orca <- simplex(SRKW.csv$SR_Orca,lib=c(1,round(length(SRKW.csv$SR_Orca)/2)),pred=c(round(length(SRKW.csv$SR_Orca)/2)+1,length(SRKW.csv$SR_Orca)),E=c(2:10)) # ORca
sim_sealionpup <- simplex(sealion.csv$Pup.count,lib=c(1,round(length(sealion.csv$Pup.count)/2)),pred=c(round(length(sealion.csv$Pup.count)/2)+1,length(sealion.csv$Pup.count)),E=c(2:10)) # Sealion pups
sim_sealionmale <- simplex(sealion.csv$Male,lib=c(1,round(length(sealion.csv$Male)/2)),pred=c(round(length(sealion.csv$Male)/2)+1,length(sealion.csv$Male)),E=c(2:10)) # Sealion Males

# We present the results showing the relationship between the predictive skill (ρ) and the embedding dimension (E)
## Plot predictive skill (rho) vs embedding dimension (E) 
par(mfrow=c(1,1),mar=c(4,4,1,1))
plot(rho~E,data=sim_FChnk,type="l",xlab="Embedding dimension (E)",ylab=expression(rho),ylim=c(-0.4,0.8),col=2,main="Ice Harbor Dam Fall Chinook, determine optimal E")
plot(rho~E,data=sim_SChnk,type="l",xlab="Embedding dimension (E)",ylab=expression(rho),ylim=c(-0.4,0.8),col=1,main="Ice Harbor Dam Sring/Summer Chinook, determine optimal E")
plot(rho~E,data=sim_PDO,type="l",xlab="Embedding dimension (E)",ylab=expression(rho),ylim=c(-0.4,0.8),col=1,main="PDO, determine optimal E")
plot(rho~E,data=sim_orca,type="l",xlab="Embedding dimension (E)",ylab=expression(rho),ylim=c(-0.4,0.8),col=1,main="Southern Resident orcas, determine optimal E")
plot(rho~E,data=sim_sealionpup,type="l",xlab="Embedding dimension (E)",ylab=expression(rho),ylim=c(-0.4,0.8),col=1,main="Sea lion pup counts, determine optimal E")
plot(rho~E,data=sim_sealionmale,type="l",xlab="Embedding dimension (E)",ylab=expression(rho),ylim=c(-0.8,0),col=1,main="Sea lion male population estimate, determine optimal E")

## The optimal embedding dimension determined by maximizing rho
E_FChnk <-sim_FChnk[which.max(sim_FChnk$rho),"E"][1]# The optimal E of IHD Fall chinook
E_SChnk <-sim_SChnk[which.max(sim_SChnk$rho),"E"][1]# The optimal E of IHD Spring/Summer chinook
E_PDO <-sim_PDO[which.max(sim_PDO$rho),"E"][1]# The optimal E of PDO
E_orca <-sim_orca[which.max(sim_orca$rho),"E"][1]# The optimal E of southern resident orca population
E_sealionpup <-sim_sealionpup[which.max(sim_sealionpup$rho),"E"][1]# The optimal E of sea lion pup count data
E_sealionmale <-sim_sealionmale[which.max(sim_sealionmale$rho),"E"][1]# The optimal E of  male sea lion population estimates
```

Distinguishing nonlinear dynamical systems from linear stochastic systems and quantifying the nonlinearity

The degree of state dependency reflects the nonlinearity of a dynamical system. State dependency (nonlinearity) can be quantified by S-map analysis (S-map stands for ‘‘sequential locally weighted global linear map’’ (Sugihara 1994)). 

Similar to simplex projection, S-map also provides forecasts in state space. However, instead of using only neighboring points surrounding the predictee, S-map makes forecasts using the whole library of points with certain weights (hence the name, locally weighted global linear map). In fact, S-map analysis is a locally weighted linear regression performed under the state space associated with a weighting function in the form of an exponential decay kernel, w(d) = exp(􏰀hd/dm). Here, d is the distance between the predictee and each library point, and dm is the mean distance of all paired library points. The parameter h controls the degree of state dependency. If h = 0, all library points have the same weight regardless of the local state of the predictee; mathematically, this model reduces to linear autoregressive model. In contrast, if h > 0, the forecast given by the S-map depends on the local state of the predictee, and thus produces locally different fittings. Therefore, by comparing the performance of equivalent linear (h = 0) and nonlinear (h > 0) S-map models, one can distinguish nonlinear dynamical systems from linear stochastic systems.

S-map analysis 

Using the function rEDM::s_map(), we calculate the one-step forward forecast by S-map analysis. Again, we divide the time series into two halves, one for library, lib, and another for out-of-sample prediction, pred. The embedding dimensions have been already determined by simplex projection  in the previous section. Then, we specify a sequence of testing state-dependency parameters θ from 0 to 2 with an increment of 0.1 by the argument, theta=seq(0,2,0.1) which executes S-map by trial-and-error using different θ. Finally, we demonstrate the results showing the relationship between the predictive skills (ρ) and state-dependency parameters (θ). Again, the criterion maximizing predictive skill is applied to determine the optimal θ.

```{r}
# S map 
smap_FChnk <- s_map(dat$FChnk,E=E_FChnk,lib=c(1,n),pred=c(n+1,length(dat$FChnk)),theta=seq(0,10,1))
smap_SChnk <- s_map(dat$SChnk,E=E_SChnk,lib=c(1,n),pred=c(n+1,length(dat$SChnk)),theta=seq(0,10,1))
smap_PDO <- s_map(PDO.csv$PDOya,E=E_PDO,lib=c(1,round(length(PDO.csv$PDOya)/2)),pred=c(round(length(PDO.csv$PDOya)/2)+1,length(PDO.csv$PDOya)),theta=seq(0,10,1))
smap_orca <- s_map(SRKW.csv$SR_Orca, E=E_orca, lib=c(1,round(length(SRKW.csv$SR_Orca)/2)),pred=c(round(length(SRKW.csv$SR_Orca)/2)+1,length(SRKW.csv$SR_Orca)),theta=seq(0,10,1)) # ORca
smap_sealionpup <- s_map(sealion.csv$Pup.count, E=E_sealionpup, lib=c(1,round(length(sealion.csv$Pup.count)/2)),pred=c(round(length(sealion.csv$Pup.count)/2)+1,length(sealion.csv$Pup.count)),theta=seq(0,10,1)) # Sealion pup count
smap_sealionmale <- s_map(sealion.csv$Male, E=E_sealionmale, lib=c(1,round(length(sealion.csv$Male)/2)),pred=c(round(length(sealion.csv$Male)/2)+1,length(sealion.csv$Male)),theta=seq(0,10,1)) # Male sea lion population

## Plot predictive skill (rho) vs state-dependency parameter (theta) 
plot(rho~theta,data=smap_FChnk,type="l",xlab=expression(theta),ylab=expression(rho),ylim=c(0.65,.95),col=2,main="Ice Harbor Dam Fall Chinook, determine optimal theta")
plot(rho~theta,data=smap_SChnk,type="l",xlab=expression(theta),ylab=expression(rho),ylim=c(0.5,.7),col=2,main="Ice Harbor Dam Spring/Summer Chinook, determine optimal theta")
plot(rho~theta,data=smap_PDO,type="l",xlab=expression(theta),ylab=expression(rho),ylim=c(0,0.6),col=2,main="PDO, determine optimal theta")
plot(rho~theta,data=smap_orca,type="l",xlab=expression(theta),ylab=expression(rho),ylim=c(0.5,.7),col=2,main="Southern resident orcas, determine optimal theta")
plot(rho~theta,data=smap_sealionpup,type="l",xlab=expression(theta),ylab=expression(rho),ylim=c(-0.2,0.2),col=2,main="Sea lions, determine optimal theta")
plot(rho~theta,data=smap_sealionmale,type="l",xlab=expression(theta),ylab=expression(rho),ylim=c(-0,0.5),col=2,main="Male sea lion population, optimal theta")

## The optimal theta determined by maximizing rho
the_FChnk <- smap_FChnk[which.max(smap_FChnk$rho),"theta"][1]
the_SChnk <- smap_SChnk[which.max(smap_SChnk$rho),"theta"][1]
the_PDO <- smap_PDO[which.max(smap_PDO$rho),"theta"][1]
the_orca <- smap_orca[which.max(smap_orca$rho),"theta"][1]
the_sealionpup <- smap_sealionpup[which.max(smap_sealionpup$rho),"theta"][1]
the_sealionmale <- smap_sealionmale[which.max(smap_sealionmale$rho),"theta"][1]
```
Determining causal variables by convergent cross mapping (CCM)

EDM can be used to reveal causation between variables. Two variables are causally linked if they interact in the same dynamical system. Following Takens’ theorem, the system manifold reconstructed from univariate embedding (State Space Reconstruction using a single variable) gives a 1-1 map to the original system, i.e., topologically invariance. Because all manifolds reconstructed from univariates give 1-1 maps to the original manifold, it is not surprising that all the reconstructed manifolds result in 1-1 mappings if they are causally linked. Based on this idea, Sugihara et al. (2012) developed a cross-mapping algorithm to test the causation between a pair of variables in dynamical systems. This algorithm predicts the current quantity of one variable M1 using the time lags of another variable M2 and vice versa. If M1 and M2 belong to the same dynamical system (i.e., they are causally linked), the cross-mapping between them shall be ‘‘convergent.’’ Convergence means that the cross-mapping skill (q) improves with increasing library size. This is because more data in the library makes the reconstructed manifold denser, and the highly resolved attractor improves the accuracy of prediction based on neighboring points (i.e., simplex projection). Sugihara et al. (2012) stated that convergence is a practical criterion to test causation, and called this phenomenon convergent cross-mapping (CCM).

To evaluate convergence in cross-mapping, the state space is reconstructed using different library lengths (L) subsampled randomly from time series. Here, Li starts from the minimal library length, L0, which is equal to the embedding dimension, to the maximal library length, Lmax, which equal to the whole length of the time series. To test the convergence of CCM, two approaches are widely used. First, the convergence can be tested by investigating how the cross- mapping skill changes with respect to the library size (e.g., trend or increment). For example, one can consider the following two statistical criteria: (1) testing the existence of a significant monotonic increasing trend in q(L) using Kendall’s s test, and (2) testing the significance of the improvement in q(L) by Fisher’s Dq Z test, which checks whether the cross-mapping skill obtained under the maximal library length (q(Lmax)) is significantly higher than that obtained using the minimal library length (q(L0)). The convergence of CCM is deemed significant when both Kendall’s s test and Fisher’s Dq Z test are significant. 

Note that, the direction of cross-mapping is opposite to the direction of cause-effect. That is, a convergent cross-mapping from M2(t) to M1(t) indicates that M1 causes M2. This is because M1, as a causal variable driving M2, has left its footprints on M2(t). The footprints of M1 are transcribed on the past history of M2, and thus M2 is able to predict the current value of M1.

Here we test if the PDO cycle is causing Chinook population fluctuations and vice versa. 

```{r}

# Fall Chinook cross-mapping PDO (i.e. testing PDO as a cause of Fall chinook)

# select PDO data between 1962 and 2018 - years for Ice Harbor Dam counts
dat$PDO <- PDO.csv$PDOya[which(PDO.csv$Year>1961)]
dat <- data.frame(dat)

# Determine the embedding dimension
E.test.PDO=NULL
for(E.t in 2:9){
  E.temp <- ccm(dat, E = E.t, lib_column = "FChnk", target_column = "PDO", lib_sizes = 57, num_samples = 1, tp=-1,random_libs = F)
  E.test.PDO=rbind(E.test.PDO,E.temp)}
(E_ccm_PDO <- E.test.PDO$E[which.max(E.test.PDO$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_ccm_PDO,57,2))

# CCM analysis with varying library size (L)
FChnk_xmap_PDO <- ccm(dat, E=E_ccm_PDO,lib_column="FChnk", target_column="PDO",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nCPq=as.matrix(aggregate(FChnk_xmap_PDO[,c('rho')],by = list(as.factor(FChnk_xmap_PDO$lib_size)), quantile)[,'x'])
apply(nCPq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Fall Chinook cross-mapping PDO
plot(nCPq[,3]~libs,type="l",col="red",ylim=c(0.2,0.6),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nCPq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nCPq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

###########################################################
# PDO cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of PDO - makes no sense, just exploring the methodology)
# Determine the embedding dimension
E.test.FChnk=NULL
for(E.t in 2:9){
  E.temp <- ccm(dat, E = E.t, lib_column = "PDO", target_column = "FChnk", lib_sizes = 57, num_samples = 1, tp=-1,random_libs = F)
  E.test.FChnk=rbind(E.test.FChnk,E.temp)}
E_ccm_FChnk <- E.test.FChnk$E[which.max(E.test.FChnk$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_ccm_FChnk,57,2))

# CCM analysis with varying library size (L)
PDO_xmap_FChnk <- ccm(dat, E=E_ccm_FChnk,lib_column="PDO", target_column="FChnk",
                lib_sizes=libs, num_samples=50, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nPCq=as.matrix(aggregate(PDO_xmap_FChnk[,c('rho')],by = list(as.factor(PDO_xmap_FChnk$lib_size)), quantile)[,'x'])
apply(nPCq[,2:5],2,MannKendall)

# PDO cross-mapping Fall Chinook 
lines(nPCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nPCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nPCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(30,0.3,c("Fall Chinook cross-mapping PDO","PDO cross-mapping Fall Chinook"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'FChnk'],dat[,'PDO']),lty=3)

```
Significant effect of PDO on IHR Fall chinook population size (monotonic increasing trend in red) but no significant effect of chinook on PDO (in blue, as expected of course)

```{r}
## Spring/Summer Chinook interaction with PDO


# Spring/Summer Chinook cross-mapping PDO (i.e. testing PDO as a cause of Spring/Summer chinook)

# Determine the embedding dimension
E.test.PDO=NULL
for(E.t in 2:9){
  E.temp <- ccm(dat, E = E.t, lib_column = "SChnk", target_column = "PDO", lib_sizes = 57, num_samples = 1, tp=-1,random_libs = F)
  E.test.PDO=rbind(E.test.PDO,E.temp)}
E_ccm_PDO <- E.test.PDO$E[which.max(E.test.PDO$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_ccm_PDO,57,2))

# CCM analysis with varying library size (L)
SChnk_xmap_PDO <- ccm(dat, E=E_ccm_PDO,lib_column="SChnk", target_column="PDO",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nCPq=as.matrix(aggregate(SChnk_xmap_PDO[,c('rho')],by = list(as.factor(SChnk_xmap_PDO$lib_size)), quantile)[,'x'])
apply(nCPq[,2:5],2,MannKendall)


# Plot forecast skill vs library size
# Spring/Summer Chinook cross-mapping PDO
plot(nCPq[,3]~libs,type="l",col="red",ylim=c(0.2,0.6),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nCPq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nCPq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile


###########################################################
# PDO cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of PDO - makes no sense, just exploring the methodology)
# Determine the embedding dimension
E.test.SChnk=NULL
for(E.t in 2:9){
  E.temp <- ccm(dat, E = E.t, lib_column = "PDO", target_column = "SChnk", lib_sizes = 57, num_samples = 1, tp=-1,random_libs = F)
  E.test.SChnk=rbind(E.test.SChnk,E.temp)}
(E_ccm_SChnk <- E.test.SChnk$E[which.max(E.test.SChnk$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_ccm_SChnk,57,2))

# CCM analysis with varying library size (L)
PDO_xmap_SChnk <- ccm(dat, E=E_ccm_SChnk,lib_column="PDO", target_column="SChnk",
                lib_sizes=libs, num_samples=50, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nPCq=as.matrix(aggregate(PDO_xmap_SChnk[,c('rho')],by = list(as.factor(PDO_xmap_SChnk$lib_size)), quantile)[,'x'])
apply(nPCq[,2:5],2,MannKendall)


# PDO cross-mapping Spring/Summer Chinook 
lines(nPCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nPCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nPCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(30,0.25,c("S/S Chinook cross-mapping PDO","PDO cross-mapping S/S Chinook"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'SChnk'],dat[,'PDO']),lty=3)

```
Significant effect of PDO on IHR Spring/Summer chinook population size (monotonic increasing trend in red) but no significant effect of chinook on PDO (in blue, as expected of course)

```{r}
## Sealion - Chinook interaction 

# select Chinook data between 1975 and 2014 - years for sea lion pup counts and male sea lion populaiton estimates
sealion.csv$FChnk <- dat$FChnk[which(IHR_Fall_Chinook.csv$year>1974 & IHR_Fall_Chinook.csv$year<2015)]
sealion.csv$SChnk <- dat$SChnk[which(IHR_SprSum_Chinook.csv$year>1974 & IHR_SprSum_Chinook.csv$year<2015)]
sealion.csv$PDO <- PDO.csv$PDOya[which(PDO.csv$Year>1974 & PDO.csv$Year<2015)]
sealion.csv$SR_Orca <- PDO.csv$PDOya[which(PDO.csv$Year>1974 & PDO.csv$Year<2015)]

# Fall Chinook cross-mapping sealion pup count (i.e. testing sea lion pup count as a cause of Fall chinook)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:9){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "FChnk", target_column = "Pup.count", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
(E_FChnk_ccmE_SL <- E.test$E[which.max(E.test$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_FChnk_ccmE_SL*2,40,2))

# CCM analysis with varying library size (L)
FChnk_ccm_SL <- ccm(sealion.csv, E=E_FChnk_ccmE_SL,lib_column="FChnk", target_column="Pup.count",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nFC_SLq=as.matrix(aggregate(FChnk_ccm_SL[,c('rho')],by = list(as.factor(FChnk_ccm_SL$lib_size)), quantile)[,'x'])
apply(nFC_SLq[,2:5],2,MannKendall)


# Plot forecast skill vs library size
# Fall Chinook cross-mapping sealion pup count (i.e. testing sea lion pup count as a cause of Fall chinook)
plot(nFC_SLq[,3]~libs,type="l",col="red",ylim=c(0.6,0.9),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nFC_SLq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nFC_SLq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

###########################################################
# Sealion pup count cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of sea lion pup count)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:9){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "Pup.count", target_column = "FChnk", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
(E_SL_ccmE_FChnk <- E.test$E[which.max(E.test$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SL_ccmE_FChnk,40,2))

# CCM analysis with varying library size (L)
SL_ccm_FChnk <- ccm(sealion.csv, E=E_SL_ccmE_FChnk,lib_column="Pup.count", target_column="FChnk",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSL_FCq=as.matrix(aggregate(SL_ccm_FChnk[,c('rho')],by = list(as.factor(SL_ccm_FChnk$lib_size)), quantile)[,'x'])
apply(nSL_FCq[,2:5],2,MannKendall)

# Sealion pup count cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of sea lion pup count)
lines(nSL_FCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nSL_FCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nSL_FCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(20,0.65,c("Fall Chinook xmap sea lion pup count","Sea lion pup count xmap Fall Chinook"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'FChnk'],dat[,'PDO']),lty=3)

```
No significant effect of sea lion pup counts on IHR Fall Chinook (in red), but a significant effect of IHR Fall Chinook on sea lion pup counts (in blue). 

```{r}
# Spring/Summer Chinook cross-mapping sealion pup count (i.e. testing sea lion pup count as a cause of S/S chinook)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "SChnk", target_column = "Pup.count", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_SChnk_ccmE_SL <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SChnk_ccmE_SL*2,40,2))

# CCM analysis with varying library size (L)
SChnk_ccm_SL <- ccm(sealion.csv, E=E_SChnk_ccmE_SL,lib_column="SChnk", target_column="Pup.count",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSC_SLq=as.matrix(aggregate(SChnk_ccm_SL[,c('rho')],by = list(as.factor(SChnk_ccm_SL$lib_size)), quantile)[,'x'])
apply(nSC_SLq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Spring/Summer Chinook cross-mapping sealion pup count (i.e. testing sea lion pup count as a cause of S/S chinook)
plot(nSC_SLq[,3]~libs,type="l",col="red",ylim=c(0.5,0.7),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nSC_SLq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nSC_SLq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile


###########################################################
# Sealion cross-mapping Spring/Summer Chinook (i.e. testing Spring/Summer chinook as a cause of sea lions)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "Pup.count", target_column = "SChnk", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_SL_ccmE_SChnk <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SL_ccmE_SChnk*2,40,2))

# CCM analysis with varying library size (L)
SL_ccm_SChnk <- ccm(sealion.csv, E=E_SL_ccmE_SChnk,lib_column="Pup.count", target_column="SChnk",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSL_SCq=as.matrix(aggregate(SL_ccm_SChnk[,c('rho')],by = list(as.factor(SL_ccm_SChnk$lib_size)), quantile)[,'x'])
apply(nSL_SCq[,2:5],2,MannKendall)




# Sealion pupcount cross-mapping Spring/Summer Chinoon (i.e. testing Spring/Summer chinook as a cause of sea lion pup count)
lines(nSL_SCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nSL_SCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nSL_SCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(20,0.55,c("S/S Chinook xmap sea lion pup count","Sea lion pup count xmap S/S Chinook"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'SChnk'],dat[,'PDO']),lty=3)

```
```{r}
# Fall Chinook cross-mapping male sea lion population estimate (i.e. testing male sea lions as a cause of Fall chinook)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:9){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "FChnk", target_column = "Male", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
(E_FChnk_ccmE_SLM <- E.test$E[which.max(E.test$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_FChnk_ccmE_SLM*2,40,2))

# CCM analysis with varying library size (L)
FChnk_ccm_SLM <- ccm(sealion.csv, E=E_FChnk_ccmE_SLM,lib_column="FChnk", target_column="Male",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nFC_SLMq=as.matrix(aggregate(FChnk_ccm_SLM[,c('rho')],by = list(as.factor(FChnk_ccm_SLM$lib_size)), quantile)[,'x'])
apply(nFC_SLMq[,2:5],2,MannKendall)


# Plot forecast skill vs library size
# Fall Chinook cross-mapping male sea lion population estimate (i.e. testing male sea lions as a cause of Fall chinook)
plot(nFC_SLMq[,3]~libs,type="l",col="red",ylim=c(0.75,1),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nFC_SLMq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nFC_SLMq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

###########################################################
# Male sea lions cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of Male sea lion population estimate)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:9){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "Male", target_column = "FChnk", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
(E_SLM_ccmE_FChnk <- E.test$E[which.max(E.test$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SLM_ccmE_FChnk,40,2))

# CCM analysis with varying library size (L)
SLM_ccm_FChnk <- ccm(sealion.csv, E=E_SLM_ccmE_FChnk,lib_column="Male", target_column="FChnk",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSLM_FCq=as.matrix(aggregate(SLM_ccm_FChnk[,c('rho')],by = list(as.factor(SLM_ccm_FChnk$lib_size)), quantile)[,'x'])
apply(nSLM_FCq[,2:5],2,MannKendall)

# Sealion pup count cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of sea lion pup count)
lines(nSLM_FCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nSLM_FCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nSLM_FCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(25,0.83,c("Fall Chinook xmap male sea lion","Male sea lion xmap Fall Chinook"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'FChnk'],dat[,'PDO']),lty=3)

```
Significant 2-way interaction between Fall Chinook and male sea lion population estimates!

```{r}
# Orca cross-mapping male sea lion estimates (i.e. testing male sea lion estimates as a cause of Orca dynamics)
SRKW <- NULL
SRKW$Male <- sealion.csv$Male[which(sealion.csv$Year>1975 & sealion.csv$Year<2015)]
SRKW$SR_Orca <- SRKW.csv$SR_Orca[which(SRKW.csv$Year>1975 & SRKW.csv$Year<2015)]
SRKW <- data.frame(SRKW)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(SRKW, E = E.t, lib_column = "SR_Orca", target_column = "Male", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_SR_Orca_ccmE_SLM <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SR_Orca_ccmE_SLM*2,40,2))

# CCM analysis with varying library size (L)
SR_Orca_ccm_SLM <- ccm(SRKW, E=E_SR_Orca_ccmE_SLM,lib_column="SR_Orca", target_column="Male",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nKW_SLMq=as.matrix(aggregate(SR_Orca_ccm_SLM[,c('rho')],by = list(as.factor(SR_Orca_ccm_SLM$lib_size)), quantile)[,'x'])
apply(nKW_SLMq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Orca cross-mapping male sea lion estimates (i.e. testing male sea lion estimates as a cause of Orca dynamics)

plot(nKW_SLMq[,3]~libs,type="l",col="red",ylim=c(0.4,0.9),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nKW_SLMq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nKW_SLMq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile


###########################################################
# Male sea lion cross-mapping Orcas (i.e. testing Orcas as a cause of male sea lions)


# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(SRKW, E = E.t, lib_column = "Male", target_column = "SR_Orca", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_SLM_ccmE_SR_Orca <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SLM_ccmE_SR_Orca*2,40,2))

# CCM analysis with varying library size (L)
SLM_ccm_SR_Orca <- ccm(SRKW, E=E_SLM_ccmE_SR_Orca,lib_column="Male", target_column="SR_Orca",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSLM_KWq=as.matrix(aggregate(SLM_ccm_SR_Orca[,c('rho')],by = list(as.factor(SLM_ccm_SR_Orca$lib_size)), quantile)[,'x'])
apply(nSLM_KWq[,2:5],2,MannKendall)

# Male sea lion cross-mapping Orcas (i.e. testing Orcas as a cause of male sea lions)
lines(nSLM_KWq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nSLM_KWq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nSLM_KWq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(20,0.55,c("Orca xmap male sea lion","Male sea lion xmap Orca"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'SChnk'],dat[,'PDO']),lty=3)

```

```{r}
# Spring/Summer Chinook cross-mapping male sea lion estimates (i.e. testing male sea lion estimates as a cause of S/S chinook)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "SChnk", target_column = "Male", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_SChnk_ccmE_SLM <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SChnk_ccmE_SLM*2,40,2))

# CCM analysis with varying library size (L)
SChnk_ccm_SLM <- ccm(sealion.csv, E=E_SChnk_ccmE_SLM,lib_column="SChnk", target_column="Male",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSC_SLMq=as.matrix(aggregate(SChnk_ccm_SLM[,c('rho')],by = list(as.factor(SChnk_ccm_SLM$lib_size)), quantile)[,'x'])
apply(nSC_SLMq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Spring/Summer Chinook cross-mapping sealion pup count (i.e. testing sea lion pup count as a cause of S/S chinook)
plot(nSC_SLMq[,3]~libs,type="l",col="red",ylim=c(0.4,0.9),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nSC_SLMq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nSC_SLMq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile


###########################################################
# Male sea lion cross-mapping Spring/Summer Chinook (i.e. testing Spring/Summer chinook as a cause of male sea lions)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "Male", target_column = "SChnk", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_SLM_ccmE_SChnk <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SLM_ccmE_SChnk*2,40,2))

# CCM analysis with varying library size (L)
SLM_ccm_SChnk <- ccm(sealion.csv, E=E_SLM_ccmE_SChnk,lib_column="Male", target_column="SChnk",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSLM_SCq=as.matrix(aggregate(SLM_ccm_SChnk[,c('rho')],by = list(as.factor(SLM_ccm_SChnk$lib_size)), quantile)[,'x'])
apply(nSLM_SCq[,2:5],2,MannKendall)

# Sealion pupcount cross-mapping Spring/Summer Chinoon (i.e. testing Spring/Summer chinook as a cause of sea lion pup count)
lines(nSLM_SCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nSLM_SCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nSLM_SCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(20,0.55,c("S/S Chinook xmap male sea lion","Male sea lion xmap S/S Chinook"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'SChnk'],dat[,'PDO']),lty=3)

```


Slight but significant effect of Spring/Summer Chinook on male sea lion population estimates but no significant effect of sea lions on S/S Chinook. 

```{r}
## Orca - Chinook interaction 

# select Chinook and PDO data between 1976 and 2018 - years for SR Orca population counts
SRKW.csv$FChnk <- dat$FChnk[which(IHR_Fall_Chinook.csv$year>1975 & IHR_Fall_Chinook.csv$year<2019)]
SRKW.csv$SChnk <- dat$SChnk[which(IHR_SprSum_Chinook.csv$year>1975 & IHR_SprSum_Chinook.csv$year<2019)]
SRKW.csv$PDO <- PDO.csv$PDOya[which(PDO.csv$Year>1975 & PDO.csv$Year<2019)]

# Fall Chinook cross-mapping orcas (i.e. testing orcas as a cause of Fall chinook)



# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(SRKW.csv, E = E.t, lib_column = "FChnk", target_column = "SR_Orca", lib_sizes = 43, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
(E_FChnk_ccmE_orca <- E.test$E[which.max(E.test$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_FChnk_ccmE_orca*2,43,2))

# CCM analysis with varying library size (L)
FChnk_ccm_orca <- ccm(SRKW.csv, E=E_FChnk_ccmE_orca,lib_column="FChnk", target_column="SR_Orca",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nFC_orcaq=as.matrix(aggregate(FChnk_ccm_orca[,c('rho')],by = list(as.factor(FChnk_ccm_orca$lib_size)), quantile)[,'x'])
apply(nFC_orcaq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Fall Chinook cross-mapping orca (i.e. testing orcas as a cause of Fall chinook)
plot(nFC_orcaq[,3]~libs,type="l",col="red",ylim=c(0.6,0.9),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nFC_orcaq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nFC_orcaq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

###########################################################
# Orcas cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of orca populations)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(SRKW.csv, E = E.t, lib_column = "SR_Orca", target_column = "FChnk", lib_sizes = 43, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
(E_orca_ccmE_FChnk <- E.test$E[which.max(E.test$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_orca_ccmE_FChnk*2,43,2))

# CCM analysis with varying library size (L)
orca_ccm_FChnk <- ccm(SRKW.csv, E=E_orca_ccmE_FChnk,lib_column="SR_Orca", target_column="FChnk",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
norca_FCq=as.matrix(aggregate(orca_ccm_FChnk[,c('rho')],by = list(as.factor(orca_ccm_FChnk$lib_size)), quantile)[,'x'])
apply(norca_FCq[,2:5],2,MannKendall)



# orca cross-mapping Fall Chinoon (i.e. testing Fall chinook as a cause of orcas)
lines(norca_FCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(norca_FCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(norca_FCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(30,0.65,c("Fall Chinook cross-mapping orcas","Orcas cross-mapping Fall chinook"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'FChnk'],dat[,'PDO']),lty=3)

```
Significant 2-way interaction between Fall Chinook at IHR dam and the Southern Resident orca population

```{r}
# Spring/Summer Chinook cross-mapping orca (i.e. testing orcas as a cause of S/S chinook)


# Determine the embedding dimension
E.test=NULL
for(E.t in 2:9){
  E.temp <- ccm(SRKW.csv, E = E.t, lib_column = "SChnk", target_column = "SR_Orca", lib_sizes = 43, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_SChnk_ccmE_orca <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SChnk_ccmE_orca*2,43,2))

# CCM analysis with varying library size (L)
SChnk_ccm_orca <- ccm(SRKW.csv, E=E_SChnk_ccmE_orca,lib_column="SChnk", target_column="SR_Orca",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSC_orcaq=as.matrix(aggregate(SChnk_ccm_orca[,c('rho')],by = list(as.factor(SChnk_ccm_orca$lib_size)), quantile)[,'x'])
apply(nSC_orcaq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Spring/Summer Chinook cross-mapping orca (i.e. testing orcas as a cause of Spring/Summer chinook)
plot(nSC_orcaq[,3]~libs,type="l",col="red",ylim=c(0,1),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nSC_orcaq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nSC_orcaq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile


###########################################################
# orca cross-mapping Spring/Summer Chinook (i.e. testing Spring/Summer chinook as a cause of Orcas)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:9){
  E.temp <- ccm(SRKW.csv, E = E.t, lib_column = "SR_Orca", target_column = "SChnk", lib_sizes = 43, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_orca_ccmE_SChnk <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_orca_ccmE_SChnk*2,43,2))

# CCM analysis with varying library size (L)
orca_ccm_SChnk <- ccm(SRKW.csv, E=E_orca_ccmE_SChnk,lib_column="SR_Orca", target_column="SChnk",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
norca_SCq=as.matrix(aggregate(orca_ccm_SChnk[,c('rho')],by = list(as.factor(orca_ccm_SChnk$lib_size)), quantile)[,'x'])
apply(norca_SCq[,2:5],2,MannKendall)

# orca cross-mapping Spring/Summer Chinoon (i.e. testing Spring/Summer chinook as a cause of orcas)
lines(norca_SCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(norca_SCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(norca_SCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(20,0.55,c("Spring/Summer Chinook cross-mapping orcas","Orcas cross-mapping Spring/Summer Chinook"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'SChnk'],dat[,'PDO']),lty=3)

```
Significant 2-way interaction between Spring/Summer Chinook at IHR dam and the Southern Resident orca population. Although significant, this interaction seems less strong than that between Fall Chinook and orcas.

```{r}
# PDO cross-mapping sea lion pup counts (i.e. testing sea lion pup counts as a cause of PDO)



# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "PDO", target_column = "Pup.count", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_PDO_ccmE_SL <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_PDO_ccmE_SL*2,40,2))

# CCM analysis with varying library size (L)
PDO_ccm_SL <- ccm(sealion.csv, E=E_PDO_ccmE_SL,lib_column="PDO", target_column="Pup.count",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nPDO_SLq=as.matrix(aggregate(PDO_ccm_SL[,c('rho')],by = list(as.factor(PDO_ccm_SL$lib_size)), quantile)[,'x'])
apply(nPDO_SLq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# PDO cross-mapping sealion (i.e. testing sea lions as a cause of PDO)
plot(nPDO_SLq[,3]~libs,type="l",col="red",ylim=c(0.2,0.8),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nPDO_SLq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nPDO_SLq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

###########################################################
# Sea lion cross-mapping PDO (i.e. testing PDO as a cause of sea lions)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(sealion.csv, E = E.t, lib_column = "Pup.count", target_column = "PDO", lib_sizes = 40, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_SL_ccmE_PDO <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SL_ccmE_PDO*2,40,2))

# CCM analysis with varying library size (L)
SL_ccm_PDO <- ccm(sealion.csv, E=E_SL_ccmE_PDO,lib_column="Pup.count", target_column="PDO",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSL_PDOq=as.matrix(aggregate(SL_ccm_PDO[,c('rho')],by = list(as.factor(SL_ccm_PDO$lib_size)), quantile)[,'x'])
apply(nSL_PDOq[,2:5],2,MannKendall)


# Sealion cross-mapping PDO (i.e. testing PDO as a cause of sea lions)
lines(nSL_PDOq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nSL_PDOq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nSL_PDOq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(18,0.3,c("PDO cross-mapping sea lion pup counts","Sea lion pup counts cross-mapping PDO"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'PDO'],dat[,'PDO']),lty=3)
```
No significant effect of PDO on sea lion populations

```{r}
# PDO cross-mapping orca (i.e. testing orcas as a cause of PDO)

# Design a sequence of library size
libs <- c(seq(20,38,2))

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(SRKW.csv, E = E.t, lib_column = "PDO", target_column = "SR_Orca", lib_sizes = 43, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_PDO_ccmE_orca <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_PDO_ccmE_orca*2,43,2))

# CCM analysis with varying library size (L)
PDO_ccm_orca <- ccm(SRKW.csv, E=E_PDO_ccmE_orca,lib_column="PDO", target_column="SR_Orca",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nPDO_orcaq=as.matrix(aggregate(PDO_ccm_orca[,c('rho')],by = list(as.factor(PDO_ccm_orca$lib_size)), quantile)[,'x'])
apply(nPDO_orcaq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Spring/Summer Chinook cross-mapping orca (i.e. testing orcas as a cause of Spring/Summer chinook)
plot(nPDO_orcaq[,3]~libs,type="l",col="red",ylim=c(-0.2,0.8),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nPDO_orcaq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nPDO_orcaq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

###########################################################
# orca cross-mapping PDO (i.e. testing PDO as a cause of Orcas)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:8){
  E.temp <- ccm(SRKW.csv, E = E.t, lib_column = "SR_Orca", target_column = "PDO", lib_sizes = 43, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
E_orca_ccmE_PDO <- E.test$E[which.max(E.test$rho)[1]] # the optimal E

# Design a sequence of library size
libs <- c(seq(E_orca_ccmE_PDO*2,43,2))

# CCM analysis with varying library size (L)
orca_ccm_PDO <- ccm(SRKW.csv, E=E_orca_ccmE_PDO,lib_column="SR_Orca", target_column="PDO",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
norca_PDOq=as.matrix(aggregate(orca_ccm_PDO[,c('rho')],by = list(as.factor(orca_ccm_PDO$lib_size)), quantile)[,'x'])
apply(norca_PDOq[,2:5],2,MannKendall)

# orca cross-mapping Spring/Summer Chinoon (i.e. testing Spring/Summer chinook as a cause of orcas)
lines(norca_PDOq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(norca_PDOq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(norca_PDOq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(20,0.55,c("PDO cross-mapping orcas","Orcas cross-mapping PDO"),lty=c(1,1),col=c("red","blue"))
#abline(h=cor(dat[,'PDO'],dat[,'PDO']),lty=3)

```
```{r}
## Spring/Summer Chinook interaction with Fall Chinook 

# Fall Chinook cross-mapping Spring/Summer Chinook (i.e. testing S/S Chinook as a cause of Fall chinook)

dat.df<-data.frame(dat)
# Determine the embedding dimension
E.test=NULL
for(E.t in 2:9){
  E.temp <- ccm(dat.df, E = E.t, lib_column = "FChnk", target_column = "SChnk", lib_sizes = 57, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
(E_FChnk_ccmE_SChnk <- E.test$E[which.max(E.test$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_FChnk_ccmE_SChnk*2,57,2))

# CCM analysis with varying library size (L)
FChnk_ccm_SL <- ccm(dat.df, E=E_FChnk_ccmE_SChnk,lib_column="FChnk", target_column="SChnk",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nFC_SCq=as.matrix(aggregate(FChnk_ccm_SL[,c('rho')],by = list(as.factor(FChnk_ccm_SL$lib_size)), quantile)[,'x'])
apply(nFC_SCq[,2:5],2,MannKendall)


# Plot forecast skill vs library size
# Fall Chinook cross-mapping Spring/Summer Chinook (i.e. testing S/S Chinook as a cause of Fall chinook)
plot(nFC_SCq[,3]~libs,type="l",col="red",ylim=c(0.6,0.9),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(nFC_SCq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(nFC_SCq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

###########################################################
# Spring/Summer Chinook cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of Spring/Summer Chinook)

# Determine the embedding dimension
E.test=NULL
for(E.t in 2:9){
  E.temp <- ccm(dat.df, E = E.t, lib_column = "SChnk", target_column = "FChnk", lib_sizes = 57, num_samples = 1, tp=-1,random_libs = F)
  E.test=rbind(E.test,E.temp)}
(E_SChnk_ccmE_FChnk <- E.test$E[which.max(E.test$rho)[1]]) # the optimal E

# Design a sequence of library size
libs <- c(seq(E_SChnk_ccmE_FChnk,57,2))

# CCM analysis with varying library size (L)
SL_ccm_FChnk <- ccm(dat.df, E=E_SChnk_ccmE_FChnk,lib_column="SChnk", target_column="FChnk",
                lib_sizes=libs, num_samples=100, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
nSC_FCq=as.matrix(aggregate(SL_ccm_FChnk[,c('rho')],by = list(as.factor(SL_ccm_FChnk$lib_size)), quantile)[,'x'])
apply(nSC_FCq[,2:5],2,MannKendall)


# Spring/Summer Chinook cross-mapping Fall Chinook (i.e. testing Fall chinook as a cause of Spring/Summer Chinook)
lines(nSC_FCq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(nSC_FCq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(nSC_FCq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile

legend(20,0.65,c("Fall Chinook cross-mapping Spring/Summer Chinook","Spring/Summer Chinook cross-mapping Fall Chinook"),lty=c(1,1),col=c("red","blue"))

```



Tracking interactions in time (Code from Deyle 2016)

Focusing on Fall Chinook, the factors that appear to be causally influencing Fall Chinook in the Snake River include Spring/Summer Chinook, male sea lions PDO, and the Southern resident orcas. The optimal embedding dimension for Fall Chinook was 5, suggesting that not all of these are important. The permutation entropy analysis suggested that a time lag of tau=5 containted the most redundant information, perhaps because these were the spawners for the returning generation. So, to start, I'll consider the five-dimensional space given by Fall Chinook (t and t-5), Spring/Summer Chinook, male sea lions, PDO, and SRKW.

The SRKW time series: 43 years from 1976 to 2018 
Sea kuib time series: 40 years form 1975 to 2014

```{r}
library(Matrix) 
library(quantreg)
 


Embedding <- c("FC","FC-5","SC","PDO", "KW", "SL") 
Edim <- length(Embedding)
d <- array(data = 0, dim = c(39,Edim)) 
d[,1] <- dat$FChnk[which(IHR_Fall_Chinook.csv$year>1975 & IHR_Fall_Chinook.csv$year<2015)]
d[,2] <- dat$FChnk[which(IHR_Fall_Chinook.csv$year>1970 & IHR_Fall_Chinook.csv$year<2010)]
d[,3] <- dat$SChnk[which(IHR_SprSum_Chinook.csv$year>1975 & IHR_SprSum_Chinook.csv$year<2015)]
d[,4] <- PDO.csv$PDOya[which(PDO.csv$Year>1975 & PDO.csv$Year<2015)]
d[,5] <- SRKW.csv$SR_Orca[which(SRKW.csv$Year<2015)]
d[,6] <- sealion.csv$Male[which(sealion.csv$Year>1975 & sealion.csv$Year<2015)]

colnames(d) <-  c("FC", "FC-5","SC","PDO", "KW", "SL") 

targ_col <- 5
coeff_names <- sapply(colnames(d),function(x) paste("d", colnames(d)[targ_col], "d", x, sep = ""))
```
For the weighted linear regression, we will be
```{r}
block <- cbind(d[2:dim(d)[1],targ_col],d[1:(dim(d)[1]-1),]) 
norm_consts <- apply(block, 2, function(x) sd(x))
block <- as.data.frame(apply(block, 2, function(x) (x-mean(x))/sd(x)))
 
```
We have a few final parameters to set for the S-map regression.
```{r}

lib <- 1:dim(block)[1] 
pred <- 1:dim(block)[1] 
theta <- 3
 
```
and we need to set up output.
```{r}

coeff <- array(0,dim=c(length(pred),Edim)) 
colnames(coeff) <- coeff_names
coeff <- as.data.frame(coeff)
 
```
Finally, to stay consistent with prior applications of S-maps, we will use SVD to solve the weighted linear regression. For ease, we put this into a single function that is similar to the basic lm() function in R. The lm() function could be used instead, but it computes the regression using QR instead of SVD.
```{r}
lm_svdsolve <- function(y, x, ws, subset = seq_along(y)){ 
  x <- x[subset,]
  y <- y[subset]
  ws <- ws[subset]
  
  # prepended column of 1s for constant term in linear model
  A <- cbind(1, x) * ws 
  A_svd <- svd(A)
  
  # >>REMOVE SMALL SINGULAR VALUES<<
  s <- A_svd$d
  s_inv <- matrix(0, nrow = dim(x)[2]+1, ncol = dim(x)[2]+1) 
  for(i in seq_along(s))
  {
    if(s[i] >= max(s) * 1e-5) s_inv[i,i] <- 1/s[i]
  }

  coeff <- A_svd$v %*% s_inv %*% t(A_svd$u) %*% (ws * y)
  coeff <- t(coeff)
  
  colnames(coeff) <- c("const",colnames(x))
  return(coeff) 
}
```
Now, all the preceding code was just to set up the calculation. We now loop over each prediction point to actually calculate the S-map locally weighted regression for each prediction point. This calculation is quite simple. (1) We calculate the (normalized) Euclidian distance from the target point to the other points on the attractor. (2) These distances then become the weights for a weighted linear regression, which we solve using singular value decomposition (SVD).
```{r}
# >>CALCULATE COEFFICIENTS<<
for (ipred in 1:length(pred)){

  #target point is excluded from the fitting procedure
  libs = lib[-pred[ipred]]
  
  # >>CALCULATE WEIGHTS<<
  q <- matrix(as.numeric(block[pred[ipred],2:dim(block)[2]]), 
              ncol=Edim, nrow=length(libs), byrow = T)
  distances <- sqrt(rowSums((block[libs,2:dim(block)[2]] - q)^2)) 
  dbar <- mean(distances)
  Ws <- exp(-theta*distances/dbar)
  
  # >>REGRESS<<
  svd_fit <- lm_svdsolve(block[libs,1],block[libs,2:dim(block)[2]],Ws) 
  coeff[ipred,] <- svd_fit[-1]
}

coeff <- cbind(pred,coeff) 
colnames(coeff)[1] <- "t"
```
We can plot a time series of these coeffcients over a span of time.

```{r}

l<-dim(block[1])[1]  #number of datapoints for plotting
par(mfrow = c(1,1))
trange <- 1:l

plot(coeff[trange,"t"],coeff[trange,"dFCdFC"],type="l",col="green",xlab="time", 
     ylab=expression(partialdiff*FC / partialdiff*FC1), 
     ylim=range(coeff[trange,"dFCdFC"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)
```


```{r}
par(mfrow = c(1,1))
trange <- 1:l

plot(coeff[trange,"t"],coeff[trange,"dFCdFC-5"],type="l",col="green",xlab="time", 
     ylab=expression(partialdiff*FC / partialdiff*FC5), 
     ylim=range(coeff[trange,"dFCdFC-5"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)
```

```{r}
par(mfrow = c(1,1))
trange <- 1:l

plot(coeff[trange,"t"],coeff[trange,"dFCdSC"],type="l",col="blue",xlab="time", 
     ylab=expression(partialdiff*FC / partialdiff*SC), 
     ylim=range(coeff[trange,"dFCdSC"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)
```

```{r}
par(mfrow = c(1,1))
trange <- 1:l

plot(coeff[trange,"t"],coeff[trange,"dFCdPDO"],type="l",col="red",xlab="time", 
     ylab=expression(partialdiff*FC / partialdiff*PDO), 
     ylim=range(coeff[trange,"dFCdPDO"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)
```

```{r}
par(mfrow = c(1,1))
trange <- 1:l

plot(coeff[trange,"t"],coeff[trange,"dFCdKW"],type="l",col="black",xlab="time", 
     ylab=expression(partialdiff*FC / partialdiff*SRKW), 
     ylim=range(coeff[trange,"dFCdKW"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)

```
```{r}
par(mfrow = c(1,1))
trange <- 1:l

plot(coeff[trange,"t"],coeff[trange,"dFCdSL"],type="l",col="black",xlab="time", 
     ylab=expression(partialdiff*FC / partialdiff*SL), 
     ylim=range(coeff[trange,"dFCdSL"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)

```

We can also plot the predation coeffcient of orcas against the effect of PDO to show how they relate.
```{r}
qL <- rq(coeff$dFCdKW ~ coeff$dFCdPDO,alpha=0.05,.05) #Quantile regression
qU <- rq(coeff$dFCdKW ~ coeff$dFCdPDO,alpha=0.05,.95)
plot(coeff[1:l, 'dFCdPDO' ],coeff[1:l, 'dFCdKW' ], 
     xlab=expression(partialdiff*FC / partialdiff*PDO), 
     ylab=expression(partialdiff*FC / partialdiff*KW), 
     xlim=range(coeff[trange,"dFCdPDO"]),ylim=range(coeff[trange,"dFCdKW"]),pch=8)
abline(a=qL$coefficients[1],b=qL$coefficients[2],lty=2,col='red',lwd=2)
abline(a=qU$coefficients[1],b=qU$coefficients[2],lty=2,col='red',lwd=2)
abline(a=0,b=0,lty=1,col='grey',lwd=2) #zero line
```
```{r}
qL <- rq(coeff$dFCdFC-5 ~ coeff$dFCdPDO,alpha=0.05,.05) 
qU <- rq(coeff$dFCdFC-5 ~ coeff$dFCdPDO,alpha=0.05,.95)
plot(coeff[1:l, 'dFCdPDO' ],coeff[1:l, 'dFCdFC-5' ], 
     xlab=expression(partialdiff*FC / partialdiff*PDO), 
     ylab=expression(partialdiff*FC / partialdiff*FC-5), 
     xlim=range(coeff[trange,"dFCdPDO"]),ylim=range(coeff[trange,"dFCdFC-5"]),pch=8)
abline(a=qL$coefficients[1],b=qL$coefficients[2],lty=2,col='red',lwd=2)
abline(a=qU$coefficients[1],b=qU$coefficients[2],lty=2,col='red',lwd=2)
abline(a=0,b=0,lty=1,col='grey',lwd=2) #zero line
```
```{r}
qL <- rq(coeff$dFCdSL ~ coeff$dFCdPDO,alpha=0.05,.05) 
qU <- rq(coeff$dFCdSL ~ coeff$dFCdPDO,alpha=0.05,.95)
plot(coeff[1:l, 'dFCdPDO' ],coeff[1:l, 'dFCdSL' ], 
     xlab=expression(partialdiff*FC / partialdiff*PDO), 
     ylab=expression(partialdiff*FC / partialdiff*SL), 
     xlim=range(coeff[trange,"dFCdPDO"]),ylim=range(coeff[trange,"dFCdSL"]),pch=8)
abline(a=qL$coefficients[1],b=qL$coefficients[2],lty=2,col='red',lwd=2)
abline(a=qU$coefficients[1],b=qU$coefficients[2],lty=2,col='red',lwd=2)
abline(a=0,b=0,lty=1,col='grey',lwd=2) #zero line
```

```{r}
qL <- rq(coeff$dFCdSL ~ coeff$dFCdKW,alpha=0.05,.05) 
qU <- rq(coeff$dFCdSL ~ coeff$dFCdKW,alpha=0.05,.95)
plot(coeff[1:l, 'dFCdPDO' ],coeff[1:l, 'dFCdSL' ], 
     xlab=expression(partialdiff*FC / partialdiff*KW), 
     ylab=expression(partialdiff*FC / partialdiff*SL), 
     xlim=range(coeff[trange,"dFCd"]),ylim=range(coeff[trange,"dFCdSL"]),pch=8)
abline(a=qL$coefficients[1],b=qL$coefficients[2],lty=2,col='red',lwd=2)
abline(a=qU$coefficients[1],b=qU$coefficients[2],lty=2,col='red',lwd=2)
abline(a=0,b=0,lty=1,col='grey',lwd=2) #zero line
```

Re-run smap analysis for the Orca in order to calculate the partial interaction strengths of Male sea lions on orcas. If negative, this could explain the positive net effect that male sea lions have on Chinook. 

```{r}
Embedding <- c("FC","SC","PDO", "KW", "SL") 
Edim <- length(Embedding)
d <- array(data = 0, dim = c(39,Edim)) 
d[,1] <- dat$FChnk[which(IHR_Fall_Chinook.csv$year>1975 & IHR_Fall_Chinook.csv$year<2015)]
d[,2] <- dat$SChnk[which(IHR_SprSum_Chinook.csv$year>1975 & IHR_SprSum_Chinook.csv$year<2015)]
d[,3] <- PDO.csv$PDOya[which(PDO.csv$Year>1975 & PDO.csv$Year<2015)]
d[,4] <- SRKW.csv$SR_Orca[which(SRKW.csv$Year<2015)]
d[,5] <- sealion.csv$Male[which(sealion.csv$Year>1975 & sealion.csv$Year<2015)]

colnames(d) <-  c("FC", "SC","PDO", "KW", "SL") 

targ_col <- 4 #Target species: Orcas
coeff_names <- sapply(colnames(d),function(x) paste("d", colnames(d)[targ_col], "d", x, sep = ""))

block <- cbind(d[2:dim(d)[1],targ_col],d[1:(dim(d)[1]-1),]) 
norm_consts <- apply(block, 2, function(x) sd(x))
block <- as.data.frame(apply(block, 2, function(x) (x-mean(x))/sd(x)))


lib <- 1:dim(block)[1] 
pred <- 1:dim(block)[1] 
theta <- 3


coeff <- array(0,dim=c(length(pred),Edim)) 
colnames(coeff) <- coeff_names
coeff <- as.data.frame(coeff)
 

lm_svdsolve <- function(y, x, ws, subset = seq_along(y)){ 
  x <- x[subset,]
  y <- y[subset]
  ws <- ws[subset]
  
  # prepended column of 1s for constant term in linear model
  A <- cbind(1, x) * ws 
  A_svd <- svd(A)
  
  # >>REMOVE SMALL SINGULAR VALUES<<
  s <- A_svd$d
  s_inv <- matrix(0, nrow = dim(x)[2]+1, ncol = dim(x)[2]+1) 
  for(i in seq_along(s))
  {
    if(s[i] >= max(s) * 1e-5) s_inv[i,i] <- 1/s[i]
  }

  coeff <- A_svd$v %*% s_inv %*% t(A_svd$u) %*% (ws * y)
  coeff <- t(coeff)
  
  colnames(coeff) <- c("const",colnames(x))
  return(coeff) 
}

# >>CALCULATE COEFFICIENTS<<
for (ipred in 1:length(pred)){

  #target point is excluded from the fitting procedure
  libs = lib[-pred[ipred]]
  
  # >>CALCULATE WEIGHTS<<
  q <- matrix(as.numeric(block[pred[ipred],2:dim(block)[2]]), 
              ncol=Edim, nrow=length(libs), byrow = T)
  distances <- sqrt(rowSums((block[libs,2:dim(block)[2]] - q)^2)) 
  dbar <- mean(distances)
  Ws <- exp(-theta*distances/dbar)
  
  # >>REGRESS<<
  svd_fit <- lm_svdsolve(block[libs,1],block[libs,2:dim(block)[2]],Ws) 
  coeff[ipred,] <- svd_fit[-1]
}

coeff <- cbind(pred,coeff) 
colnames(coeff)[1] <- "t"


l<-dim(block[1])[1]  #number of datapoints for plotting
par(mfrow = c(1,1))
trange <- 1:l


plot(coeff[trange,"t"],coeff[trange,"dKWdSL"],type="l",col="green",xlab="time", 
     ylab=expression(partialdiff*KW / partialdiff*SL), 
     ylim=range(coeff[trange,"dKWdSL"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)
```

```{r}

plot(coeff[trange,"t"],coeff[trange,"dKWdFC"],type="l",col="green",xlab="time", 
     ylab=expression(partialdiff*KW / partialdiff*FC), 
     ylim=range(coeff[trange,"dKWdFC"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)
```

```{r}

plot(coeff[trange,"t"],coeff[trange,"dKWdSC"],type="l",col="green",xlab="time", 
     ylab=expression(partialdiff*KW / partialdiff*SC), 
     ylim=range(coeff[trange,"dKWdSC"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)
```


```{r}

plot(coeff[trange,"t"],coeff[trange,"dKWdPDO"],type="l",col="green",xlab="time", 
     ylab=expression(partialdiff*KW / partialdiff*PDO), 
     ylim=range(coeff[trange,"dKWdPDO"]),xlim=range(trange),lwd=2)
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)
```