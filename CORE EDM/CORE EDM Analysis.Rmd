---
title: "CORE EDM Analysis"
author: "Alison Iles"
date: "6/3/2019"
output:  pdf_document: default
          html_document
          keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#load the necessary packages. 
Note that the `echo = FALSE` parameter prevents printing of the R code.

```{r, echo=FALSE}
library(rEDM)
#library(rjags)
library(reshape2)
library(rgl)
library(ggplot2)
library(gridExtra)
library(xtable)
```

#load data

```{R}
folder <- "/Users/alisoniles/Google Drive/Coordinated Recoveries/CORE_EDM/Data/analysis ready/"      # path to folder that holds data in .csv files
data <- read.csv(paste(folder, "SRSS_cohort_prelim.csv", sep=''))
```

#normalize

```{R}
 # To focus on one stock to figure out what's going on
stock_df <- subset(data, stk == "Bear Valley Creek") 
 
# The original code normalized by cycle line. Chinook don't demonstrate a strong cycle line, so I changed the normalize_by_cycle_line function to normalize on a 1 year cycle 
    normalize_by_cycle_line <- function(ts)
{
    n <- length(ts)
    means <- rep.int(NA, times = 4) #replicate NA 4 times
    sds <- rep.int(NA, times = 4)
    mu <- rep.int(NA, times = n)
    sigma <- rep.int(NA, times = n)
    for(k in 1:1) #for each cycle line (every 4 years the population cycles in sockeye, I've changed it to 1 because there are no cycle lines for chinook)
    {
        index <- seq(from = k, to = n, by = 1) #changed by=4 to b=1.
        means[k] <- mean(ts[index], na.rm = TRUE) #mean of every 4th element of the time series
        sds[k] <- sd(ts[index], na.rm = TRUE) #standard dev.
        mu[index] <- means[k]
        sigma[index] <- sds[k]
    }
    ts <- (ts - mu) / sigma  #normalize by cycle line
    df <- data.frame(cbind(ts, mu, sigma))
    return(df)
    }
    
     preprocess_stock <- function(stock_df)
    {
        n <- NROW(stock_df)  #n is the number of observations for the stock
         
        stock_df$ret <- stock_df$rec3 + c(NA, stock_df$rec4[1:(n-1)]) + c(NA, NA, stock_df$rec5[1:(n-2)]) #+ c(NA, NA, NA, stock_df$rec6[1:(n-3)]) # age-3,4,5,and 6 fish (aligned to rec3) #total returns are calculated by adding 3 year old recruits plus 4 year old recruits from the previous brood year, plus 5 year olds from two years prior...etc. This value is aligned to the rec3 brood year, not the year they are actually returning together. 
       
# Normalize on a 1 year cycle line (i.e. NO cycle line!)
        
        temp <- normalize_by_cycle_line(stock_df$eff)
        stock_df$eff_n <- temp$ts #normalized number of effective spawners
        stock_df$eff_mu <- temp$mu
        stock_df$eff_sigma <- temp$sigma
        
        temp <- normalize_by_cycle_line(stock_df$rec3)
        stock_df$rec3_n <- temp$ts #normalized 4 year old recruits
        stock_df$rec3_mu <- temp$mu
        stock_df$rec3_sigma <- temp$sigma
        
        temp <- normalize_by_cycle_line(stock_df$rec4)
        stock_df$rec4_n <- temp$ts #normalized 4 year old recruits
        stock_df$rec4_mu <- temp$mu
        stock_df$rec4_sigma <- temp$sigma

        temp <- normalize_by_cycle_line(stock_df$rec5)
        stock_df$rec5_n <- temp$ts #normalized 5 year old recruits
        stock_df$rec5_mu <- temp$mu
        stock_df$rec5_sigma <- temp$sigma
        
        temp <- normalize_by_cycle_line(stock_df$rec)
        stock_df$rec_n <- temp$ts #normalized total recruits
        stock_df$rec_mu <- temp$mu
        stock_df$rec_sigma <- temp$sigma

        return(stock_df)
    }   

     
# filter stocks we don't want
stock_data <- split(data, data$stk)    
stock_data <- lapply(stock_data, preprocess_stock) 
# lapply returns a list of the same length as X, each element of which is the result of applying FUN to the corresponding element of X.
```

#load environmental data
Before we do this, we need to test all the lags for each environmental variable to figure out which is the best to use

```{R}
env_data <- read.csv(paste(folder, "SRSS_env_prelim.csv", sep=''))

normalize <- function(block)
{
    if(NCOL(block) > 1)
    {
        n <- NROW(block)
        means <- sapply(block, mean, na.rm = TRUE)
        sds <- sapply(block, sd, na.rm = TRUE)
        return((block - matrix(rep(means, each = n), nrow = n)) / 
                   matrix(rep(sds, each = n), nrow = n))
    }
    else
        return((block - mean(block, na.rm = TRUE)) / sd(block, na.rm = TRUE))
}


make_block <- function(stock_df, env_data)
    {
        pdo_names <- "pdo_win"
        upwelling_names <- c("up_apr", "up_oct", "up_nov")
        pdo <- normalize(env_data[, pdo_names])
        upwelling <- normalize(env_data[, upwelling_names])
        
        # line up environmental data
        # lag temperature and river upwelling 2 years
        desired_years <- stock_df$yr + 2  #brood year + 2 
        index_in_env_data <- match(desired_years, env_data$year)
        index_in_stock_df <- 1:length(desired_years)
        
        upwelling_cols <- data.frame(matrix(NA, nrow = length(desired_years), ncol = NCOL(upwelling)))
        upwelling_cols[index_in_stock_df,] <- upwelling[index_in_env_data, ]
        stock_df[, upwelling_names] <- upwelling_cols
        
        # lag PDO by 2 years 
        desired_years <- stock_df$yr + 2
        index_in_env_data <- match(desired_years, env_data$year)
        pdo_cols <- data.frame(matrix(NA, nrow = length(desired_years), ncol = 1))
        pdo_cols[index_in_stock_df,] <- pdo[index_in_env_data]
        stock_df[, pdo_names] <- pdo_cols
        
        return(stock_df)
    }

block_data <- lapply(stock_data, function(stock_df) { make_block(stock_df, env_data)})

    # save and return
    save(block_data, file = "block_data.Rdata")

```

#Figure out how to concatenate the data, test for nonlinearity and run univariate EDM on just the recruit data...
```{R}
compute_nonlinearity_aggregated <- function()
{
    load("block_data.Rdata")
    ret <- lapply(block_data, function(x) {
        temp <- x$ret
        temp <- temp[is.finite(temp)]
        return((temp - mean(temp)) / sd(temp))
    })
    x <- c()
    lib <- matrix(NA, nrow = 26, ncol = 2)
    last <- 0
    for(i in 1:26)
    {
        x <- c(x, ret[[i]])
        lib[i,] <- c(last+1, last + length(ret[[i]]))
        last <- lib[i,2]
    }
    simplex_output <- simplex(x, lib = lib, pred = lib, E = 1:8, exclusion_radius = 0, silent = TRUE)
    E <- simplex_output$E[which.max(simplex_output$rho)]
    smap_output <- s_map(x, lib = lib, pred = lib, E = E, exclusion_radius = 0, silent = TRUE)
    theta <- smap_output$theta[which.max(smap_output$rho)]
    
    save(simplex_output, E, smap_output, theta, file = "results_nonlinear_aggregated.Rdata")
    return()
}

test_nonlinearity_aggregated <- function(num_shuffles = 500)
{
    get_smap_stats <- function(x, lib, E = NULL)
    {
        if(is.null(E))
        {
            # compute E using simplex on recruits time series
            simplex_output <- simplex(x, E = 1:8, silent = TRUE)
            best_rho_E <- simplex_output$E[which.max(simplex_output$rho)]
            best_mae_E <- simplex_output$E[which.min(simplex_output$mae)]
            E <- min(best_rho_E, best_mae_E)
        }
        
        # compute theta using s-map and E 
        smap_output <- s_map(x, lib = lib, pred = lib, E = E, silent = TRUE)
        
        best_rho <- max(smap_output$rho)
        best_mae <- min(smap_output$mae)
        return(data.frame(delta_mae = best_mae - smap_output$mae[smap_output$theta == 0]))
    }
    
    load("block_data.Rdata")
    ret <- lapply(block_data, function(x) {
        temp <- x$ret
        temp <- temp[is.finite(temp)]
        return((temp - mean(temp)) / sd(temp))
    })
    x <- c()
    lib <- matrix(NA, nrow = 26, ncol = 2)
    last <- 0
    for(i in 1:26)
    {
        x <- c(x, ret[[i]])
        lib[i,] <- c(last+1, last + length(ret[[i]]))
        last <- lib[i,2]
    }
    E <- 6
    
    cat("calculating for actual data... ", sep = "")
    start_time <- proc.time()
    actual <- get_smap_stats(x, lib, E)
    delta_mae <- actual$delta_mae
    elapsed_time <- proc.time() - start_time
    cat("(", elapsed_time[3], " sec.)\n", sep = "")
    
    # null distribution
    cat("calculating for random shuffles... ", sep = "")
    start_time <- proc.time()
    null_dist <- do.call(rbind, lapply(1:num_shuffles, function(i) {
        x_shuffle <- c()
        for(i in 1:26)
        {
            n <- length(ret[[i]])
            x_shuffle <- c(x_shuffle, ret[[i]][sample(n, n)])
        }
        return(get_smap_stats(x_shuffle, lib, E))
    }))
    
    delta_mae_p = (sum(null_dist$delta_mae < delta_mae)+1) / num_shuffles
    elapsed_time <- proc.time() - start_time
    cat("(", elapsed_time[3], " sec.)\n", sep = "")
    
    save(delta_mae = delta_mae, delta_mae_p = delta_mae_p, 
         file = "test_nonlinear_aggregated.Rdata")
    return()
}

compute_nonlinearity_stock <- function()
{
    get_smap_stats <- function(x, E = NULL)
    {
        if(is.null(E))
        {
            # compute E using simplex on recruits time series
            simplex_output <- simplex(x, E = 1:8, silent = TRUE)
            best_rho_E <- simplex_output$E[which.max(simplex_output$rho)]
            best_mae_E <- simplex_output$E[which.min(simplex_output$mae)]
            E <- min(best_rho_E, best_mae_E)
        }
        
        # compute theta using s-map and E 
        smap_output <- s_map(x, E = E, silent = TRUE)
        
        best_rho <- max(smap_output$rho)
        best_mae <- min(smap_output$mae)
        return(data.frame(delta_mae = best_mae - smap_output$mae[smap_output$theta == 0]))
    }
    
    nonlinearity_for_stock <- function(stock_df, num_shuffles = 500, max_E = 8)
    {
        x <- stock_df$ret
        x <- x[is.finite(x)]
        n <- length(x)
        
        cat("calculating for actual data for ", as.character(stock_df$stk[1]), "... ", sep = "")
        start_time <- proc.time()
        simplex_output <- simplex(x, E = 1:8, silent = TRUE)
        best_rho_E <- simplex_output$E[which.max(simplex_output$rho)]
        best_mae_E <- simplex_output$E[which.min(simplex_output$mae)]
        E <- min(best_rho_E, best_mae_E)
        
        # compute theta using s-map and E 
        smap_output <- s_map(x, E = E, silent = TRUE)
        
        best_rho <- max(smap_output$rho)
        best_mae <- min(smap_output$mae)
        theta <- smap_output$theta[which.min(smap_output$mae)]
        delta_mae <- best_mae - smap_output$mae[smap_output$theta == 0]
        elapsed_time <- proc.time() - start_time
        cat("(", elapsed_time[3], " sec.)\n", sep = "")
        
        cat("calculating for random shuffles for ", as.character(stock_df$stk[1]), "... ", sep = "")
        start_time <- proc.time()
        null_dist <- do.call(rbind, lapply(1:num_shuffles, function(i) {
            x_shuffle <- x[sample(n, n)]
            return(get_smap_stats(x_shuffle, E))
        }))
        
        delta_mae_p = (sum(null_dist$delta_mae < delta_mae)+1) / num_shuffles
        elapsed_time <- proc.time() - start_time
        cat("(", elapsed_time[3], " sec.)\n", sep = "")
        
        return(list(simplex_output = simplex_output, 
                    smap_output = smap_output, 
                    E = E, 
                    theta = theta, 
                    delta_mae = delta_mae, 
                    delta_mae_p = delta_mae_p))
    }
    
    load("block_data.Rdata")
    nonlinearity_results <- lapply(block_data, nonlinearity_for_stock)
    save(nonlinearity_results, file = "results_nonlinearity_stock.Rdata")
    return(nonlinearity_results)
}


#---- nonlinear test ----
compute_nonlinearity_aggregated()
test_nonlinearity_aggregated()
compute_nonlinearity_stock()

```

