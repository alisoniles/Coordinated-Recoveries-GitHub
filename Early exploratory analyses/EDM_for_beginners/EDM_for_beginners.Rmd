---
title: "EDM_for_beginners"
author: "Alison Iles"
date: "11/13/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Empirical Dynamic Modeling for Beginners

Empirical Dynamic Modeling for Beginners
Electronic Supplementary Materials for Ecological Research
Chun-Wei Chang, Masayuki Ushio, and Chih-hao Hsieh

EDM bears a variety of utilities to investigating dynamical systems: 
(1) determining the complexity (dimensionality) of the system (Sugihara and May 1990; Hsieh et al. 2005), 
(2) distinguishing nonlinear dynamical systems from linear stochastic systems (Sugihara 1994) and quantifying the nonlinearity (i.e. state dependence) (Anderson et al. 2008; Sugihara et al. 2011), 
(3) determining causal variables (Sugihara et al. 2012), 
(4) forecasting (Sugihara and May 1990; Dixon et al. 1999; Ye et al. 2015a; Ye and Sugihara 2016), 
(5) tracking the strength and sign of interaction (Deyle et al. 2016b), and 
(6) exploring the scenario of external perturbation (Deyle et al. 2013). 


1: Simplex projection and S-map analysis 

Load package and time series
All the EDM analyses are carried out by the rEDM package. The red noise time series is generated by a difference equation specifying the value at next time step as proportional to the current value plus a random number drawn from the standard normal distribution. The logistic map time series is generated by a self-regulatory difference equation following Hsieh et al. (2005). Both models are simulated for 10000 time steps, but only the last 1000 data are used for further analyses in order to exclude the transient dynamics.

```{r}
# loading R package: rEDM
library(rEDM)
```

Simplex projection (Sugihara & May 1990)

The complexity of a system can be practically defined as the number of independent variables needed to reconstruct the attractor (i.e. dimensionality of the system). Determining the best embedding dimension E with 'Simplex projection' is a fundamental first step in all EDM analysis. 

By simplex projection, we make one-step, out-of-sample forward forecast (predict t+1 step) using different values of E to determine the optimal embedding dimension. We present the results showing the relationship between the predictive skill (ρ - the correlation coefficient between observations and forecasts) and the embedding dimension (E) (Fig. 2c & d in the main text).

Note that, in the case where the time series is rather short, leave-one-out cross-validation can be performed instead of dividing the time series into halves (Sugihara et al. 1996; Glaser et al. 2014).

```{r}
## Data loading 
dat <- read.csv('ESM2_Data_noise.csv',header=T)

## Data normalization 

# Prior to simplex projection, the time series are normalized to zero mean and unit variance.
# Red is the normalized time series of red noise
Red <- ((dat[,"R"]-mean(dat[,"R"]))/sd(dat[,"R"])) 
# Logi is the normalized time series of the logistic map
Logi <- ((dat[,"L"]-mean(dat[,"L"]))/sd(dat[,"L"]))

# The simplex projection is carried out by the function rEDM::simplex(). 
# We divide the time series into two halves. The first half is used as the library set for manifold reconstruction. The second half is used as the target for out-of-sample prediction. 
# The argument lib is the time index indicating the start (1) and the end (500) in the library set, respectively. Similarly, the argument pred indicates the time index in the prediction set. 
# We specify a sequence of testing embedding dimensions from 2 to 8 by the argument E=c(2:8), which executes the simplex projections using different embedding dimensions.
sim_r <- simplex(Red,lib=c(1,500),pred=c(501,1000),E=c(2:8))
sim_l <- simplex(Logi,lib=c(1,500),pred=c(501,1000),E=c(2:8))

# We present the results showing the relationship between the predictive skill (ρ) and the embedding dimension (E) (Fig. 2c & d in the main text).

## Plot predictive skill (rho) vs embedding dimension (E) 
par(mfrow=c(2,1),mar=c(4,4,1,1))
plot(rho~E,data=sim_r,type="l",xlab="Embedding dimension (E)",ylab=expression(rho),ylim=c(0.3,0.4),col=2,main="Red noise")
plot(rho~E,data=sim_l,type="l",xlab="Embedding dimension (E)",ylab=expression(rho),ylim=c(0.95,1.02),col=4,main="Logistic map")

## The optimal embedding dimension determined by maximizing rho
(E_r <-sim_r[which.max(sim_r$rho),"E"][1])# The optimal E of red noise
(E_l <-sim_l[which.max(sim_l$rho),"E"][1])# The optimal E of logistic map


```
By trial-and-error using different values of E for simplex projection, we determine that the best embedding dimension for red noise is E = 7 whereas that for the simple nonlinear logistic map is E = 2. In this example, the optimal E is selected based on the criterion that maximizes the predictive skill by evaluating the correlation coefficients (p) between the forecasts and observations. The results indicated that, although both time series show large fluctuations, the dimensionality (or complexity) of the logistic map is much smaller than that of the red noise.



Distinguishing nonlinear dynamical systems from linear stochastic systems and quantifying the nonlinearity

Nonlinearity is formally de- fined as the state dependency of a nonlinear dynamical system. In other words, the degree of state dependency reflects the nonlinearity of a dynamical system. State dependency (nonlinearity) can be quantified by S-map analysis (S-map stands for ‘‘sequential locally weighted global linear map’’ (Sugihara 1994)). 

Similar to simplex projection, S-map also provides forecasts in state space. However, instead of using only neighboring points surrounding the predictee, S-map makes forecasts using the whole library of points with certain weights (hence the name, locally weighted global linear map). In fact, S-map analysis is a locally weighted linear regression performed under the state space associated with a weighting function in the form of an exponential decay kernel, w(d) = exp(􏰀hd/dm). Here, d is the distance between the predictee and each library point, and dm is the mean distance of all paired library points. The parameter h controls the degree of state dependency. If h = 0, all library points have the same weight regardless of the local state of the predictee; mathe- matically, this model reduces to linear autoregressive model. In contrast, if h > 0, the forecast given by the S-map depends on the local state of the predictee, and thus produces locally different fittings. Therefore, by comparing the performance of equivalent linear (h = 0) and nonlinear (h > 0) S-map models, one can distinguish nonlinear dynamical systems from linear stochastic systems.

S-map analysis 

Using the function rEDM::s_map(), we calculate the one-step forward forecast by S-map analysis. Again, we divide the time series into two halves, one for library, lib=c(1,500), and another for out-of-sample prediction, pred=c(501,1000). The embedding dimensions, E=E_r for red noise and E=E_l for the logistic map, have been already determined by simplex projection (Fig. 2c & d) in the previous section. Then, we specify a sequence of testing state-dependency parameters θ from 0 to 2 with an increment of 0.1 by the argument, theta=seq(0,2,0.1) which executes S-map by trial-and-error using different θ. Finally, we demonstrate the results showing the relationship between the predictive skills (ρ) and state-dependency parameters (θ) (Fig. 2e & f). Again, the criterion maximizing predictive skill is applied to determine the optimal θ.

```{r}
# S map for Red Noise & logistic map
smap_r <- s_map(Red,E=E_r,lib=c(1,500),pred=c(501,1000),theta=seq(0,2,0.1))
smap_l <- s_map(Logi,E=E_l,lib=c(1,500),pred=c(501,1000),theta=seq(0,2,0.1))

## Plot predictive skill (rho) vs state-dependency parameter (theta) 
plot(rho~theta,data=smap_r,type="l",xlab=expression(theta),ylab=expression(rho),ylim=c(0.4,0.5),col=2,main="Red noise")
plot(rho~theta,data=smap_l,type="l",xlab=expression(theta),ylab=expression(rho),ylim=c(0.6,1),col=4,main="Logistic map")
	
## The optimal theta determined by maximizing rho
(the_r <- smap_r[which.max(smap_r$rho),"theta"][1])
(the_l <- smap_l[which.max(smap_l$rho),"theta"][1])

```

The linear stochastic red noise does not ex- hibit any state dependency, as the S-map performance is optimized at h = 0. In contrast, the nonlinear logistic map reaches the optimal predictive skill at some h > 0, indicating the improved S-map forecast ability accom- panied with increasing state-dependency (i.e. nonlinear- ity).




Determining causal variables by convergent cross mapping (CCM)

EDM can be used to reveal causation between variables. Two variables are causally linked if they interact in the same dynamical system. Following Takens’ theorem, the system manifold reconstructed from univariate embedding (State Space Reconstruction using a single variable) gives a 1-1 map to the original system, i.e., topologically invariance. Because all manifolds reconstructed from univariates give 1-1 maps to the original manifold, it is not surprising that all the reconstructed manifolds result in 1-1 mappings if they are causally linked. Based on this idea, Sugihara et al. (2012) developed a cross-mapping algorithm to test the causation between a pair of variables in dynamical systems. This algorithm predicts the current quantity of one variable M1 using the time lags of another variable M2 and vice versa. If M1 and M2 belong to the same dynamical system (i.e., they are causally linked), the cross-mapping between them shall be ‘‘convergent.’’ Convergence means that the cross-mapping skill (q) improves with increasing library size. This is because more data in the library makes the reconstructed manifold denser, and the highly resolved attractor improves the accuracy of prediction based on neighboring points (i.e., simplex projection). Sugihara et al. (2012) stated that convergence is a practical criterion to test causation, and called this phenomenon convergent cross-mapping (CCM).

To evaluate convergence in cross-mapping, the state space is reconstructed using different library lengths (L) subsampled randomly from time series. Here, Li starts from the minimal library length, L0, which is equal to the embedding dimension, to the maximal library length, Lmax, which equal to the whole length of the time series. To test the convergence of CCM, two approaches are widely used. First, the convergence can be tested by investigating how the cross- mapping skill changes with respect to the library size (e.g., trend or increment). For example, one can consider the following two statistical criteria: (1) testing the existence of a significant monotonic increasing trend in q(L) using Kendall’s s test, and (2) testing the signifi- cance of the improvement in q(L) by Fisher’s Dq Z test, which checks whether the cross-mapping skill obtained under the maximal library length (q(Lmax)) is significantly higher than that obtained using the minimal library length (q(L0)). The convergence of CCM is deemed significant when both Kendall’s s test and Fisher’s Dq Z test are significant. 

Note that, the direction of cross-mapping is opposite to the direction of cause-effect. That is, a convergent cross-mapping from M2(t) to M1(t) indicates that M1 causes M2. This is because M1, as a causal variable driving M2, has left its footprints on M2(t). The footprints of M1 are transcribed on the past history of M2, and thus M2 is able to predict the current value of M1.

We demonstrate the efficacy of CCM to correctly identify causation using the Moran effect model and the two-species competition model, following Sugihara et al. (2012). In the Moran effect model, we simulate adult-recruitment dynamics as commonly used in fisheries. In this model, two populations do not have any biological interaction, while both are driven by the same environmental factor. Despite that no interaction exists, the shared environmental driver leads to strong correlation between the two populations (Fig. 1b). In the two-species competition model, we find no lasting correlation between the two species, as the sign of correlation flips through time (Fig. 1d), which is an example of mirage correlation, a hallmark of nonlinear systems.   

```{r}
# Loading R packages
library(rEDM)
library(Kendall)

# Loading the time series for the Moran effect and mirage correlation models 
dam <- read.csv('ESM3_Data_moran.csv',header=T) # Moran effect
dac <- read.csv('ESM4_Data_competition.csv',header=T) # Mirage correlation

# Data normalization
dac.n <- scale(dac[,-1], center = TRUE, scale = TRUE)
dam.n <- scale(dam[,-1], center = TRUE, scale = TRUE)

```

In the rEDM package, the function rEDM::ccm() is used for CCM analyses. Here, we illustrate how to implement the CCM causality test that examines whether N2 causes N1 in Moran effect model. To test this, we design a cross-mapping from N1 to N2 by the augument lib_column="N1" and target_column="N2". In CCM analysis, we firstly need to determine the best embedding dimension for the cross-mapping. At this step, we perform the cross-mapping with a fixed library size (lib_sizes = 1000). Then, we use the time lags of N1 to predict the lagged one time step values of N2 by setting the augment tp=-1 and determine the optimal E based on the hindcast skill to avoid over-fitting (Deyle et al. 2016). Similarly, we can repeat the same process to determine the embedding dimension in the cross-mapping from N2 to N1. Next, we carried out the CCM causality test with varying library size. 

In CCM analysis, we use the time lags of N1 to predict the current value of N2 (tp=0). To precisely estimate the predictive skill (ρ), we generate the 200 random samples with replacement (replace=T) for each library length L (num_samples=200). As such, we obtain the sampling distribution of predictive skill ρ(L). A random seed is setup to make the results repeatable (RNGseed=2301). Finally, we offer a simple statistical test for the convergence of CCM by Mann-Kendall Tau trend test when the null time series is not easily accessible. This is a nonparametric test for the existence of monotonic increasing trend, using the function Kendall::MannKendall(). Practically, we can evaluate the significance of causations by examining whether all the quantiles of predictive skill demonstrate a significant increasing trend with increasing library size (τ statistics significantly > 0). Similarly, we can repeat all these procedures of CCM analysis to test the causality for the two species competition model with mirage correlation.

```{r}
## CCM analysis of the Moran effect model, N1 and N2
# Design a sequence of library size
libs <- c(seq(20,80,20),seq(100,1000,100))

# Moran effect model: N1 cross-mapping N2 (i.e. testing N2 as a cause of N1)
# Determine the embedding dimension with the largest library size
E.test.n1=NULL
for(E.t in 2:8){
  cmxy.t <- ccm(dam.n, E = E.t, lib_column = "N1", target_column = "N2",
lib_sizes = 1000, num_samples = 1, tp=-1,random_libs = F)
  E.test.n1=rbind(E.test.n1,cmxy.t)}
(E_n1 <- E.test.n1$E[which.max(E.test.n1$rho)[1]]) # the optimal E

# CCM analysis with varying library size (L)
n1_xmap_n2 <- ccm(dam.n, E=E_n1,lib_column="N1", target_column="N2",
                lib_sizes=libs, num_samples=200, replace=T, RNGseed=2301)
	
# Calculate the median, maximum, and 1st & 3rd quantile of rho for each L
#Test for monotonic trend in a time series z[t] based on the Kendall rank correlation of z[t] and t. 
            #Here the median, maximum, and 1st & 3rd quantiles of rho are tested, all need to be <0.05.
n12q=as.matrix(aggregate(n1_xmap_n2[,c('rho')],by = list(as.factor(n1_xmap_n2$lib_size)), quantile)[,'x'])
apply(n12q[,2:5],2,MannKendall)

###########################################################
# Moran effect model: N2 cross-mapping N1 (i.e. testing N1 as a cause of N2)
# Determine the embedding dimension
E.test.n2=NULL
for(E.t in 2:8){
  cmxy.t <- ccm(dam.n, E = E.t, lib_column = "N2", target_column = "N1",
               lib_sizes = 1000, num_samples = 1, tp=-1, random_libs = F)
  E.test.n2=rbind(E.test.n2,cmxy.t)}
(E_n2 <- E.test.n2$E[which.max(E.test.n2$rho)[1]])

# CCM analysis
n2_xmap_n1 <- ccm(dam.n, E=E_n2,lib_column="N2", target_column="N1",
                lib_sizes=libs, num_samples=200, replace=T, RNGseed=2301)

# Calculate the (25%,50%,75%,100%) quantile for predictive skills
n21q=as.matrix(aggregate(n2_xmap_n1[,c('rho')],by = list(as.factor(n2_xmap_n1$lib_size)), quantile)[,'x'])
apply(n21q[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Plot N1 cross-mapping N2
plot(n12q[,3]~libs,type="l",col="red",ylim=c(0,1),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(n12q[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(n12q[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

# Plot N2 cross-mapping N1
lines(n21q[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(n21q[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(n21q[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(600,1,c("N1 xmap N2","N2 xmap N1"),lty=c(1,1),col=c("red","blue"))
abline(h=cor(dam[,'N1'],dam[,'N2']),lty=3)

```
Note: CCM results are typically interpreted in the opposite direction of causation. Please see 'Detecting causality in complex ecosystems' (Sugihara et al. 2012) for more details.Found overlap between lib and pred. Enabling cross-validation with exclusion radius = 0.

Following the same procedure, we apply CCM to test the mutual causation between the two competitors exhibiting mirage correlations. 

```{R}
#########################################################################
#########################################################################
## CCM analysis of the two species competition model with mirage correlation
# Design a sequence of library size
libs <- c(seq(20,80,20),seq(100,1000,100))

# Mirage correlation model: M1 cross-mapping M2 (i.e. testing M2 as a cause of M1)
# Determine the embedding dimension
E.test.x=NULL
for(E.t in 2:8){
  cmxy.t <- ccm(dac.n, E = E.t, lib_column = "M1", target_column = "M2",
lib_sizes = 1000, num_samples = 1, tp=-1,random_libs = F)
  E.test.x=rbind(E.test.x,cmxy.t)}
(E_x <- E.test.x$E[which.max(E.test.x$rho)[1]])

# CCM analysis: varying library size
x_xmap_y <- ccm(dac.n, E=E_x,lib_column="M1", target_column="M2",
                lib_sizes=libs, num_samples=200, replace=T, RNGseed=2301)

# Calculate the median, maximum, and 1st & 3rd quantiles of rho
xyq=as.matrix(aggregate(x_xmap_y[,c('rho')],by = list(as.factor(x_xmap_y$lib_size)), quantile)[,'x'])
apply(xyq[,2:5],2,MannKendall)


###########################################################
# Mirage correlation model: M2 cross-mapping M1 (i.e. testing M1 as a cause of M2)
# Determine the embedding dimension
E.test.y=NULL
for(E.t in 2:8){
  cmxy.t <- ccm(dac.n, E = E.t, lib_column = "M2", target_column = "M1",
                lib_sizes = 1000, num_samples = 1,tp=-1,random_libs = F)
  E.test.y=rbind(E.test.y,cmxy.t)}
(E_y <- E.test.y$E[which.max(E.test.y$rho)[1]])

# CCM analysis
y_xmap_x <- ccm(dac.n, E=E_y,lib_column="M2", target_column="M1",
                lib_sizes=libs, num_samples=200, replace=T, RNGseed=2301)

# Calculate the (25%,50%,75%,100%) quantile for predictive skills
yxq=as.matrix(aggregate(y_xmap_x[,c('rho')],by = list(as.factor(y_xmap_x$lib_size)), quantile)[,'x'])
apply(yxq[,2:5],2,MannKendall)

# Plot forecast skill vs library size
# Plot X cross-mapping Y
plot(xyq[,3]~libs,type="l",col="red",ylim=c(0,1),lwd=2,
     main="Convergent cross mapping CCM",xlab="Library size",ylab=expression(rho)) # median predictive skill vs library size (or we can use mean predictive skill)
lines(xyq[,2]~libs,col="red",lwd=1,lty=2) # 1st quantile 
lines(xyq[,4]~libs,col="red",lwd=1,lty=2) # 3rd quantile

# Plot Y cross-mapping X
lines(yxq[,3]~libs,col="blue",lwd=1,lty=1) # median 
lines(yxq[,2]~libs,col="blue",lwd=1,lty=2) # 1st quantile 
lines(yxq[,4]~libs,col="blue",lwd=1,lty=2) # 3rd quantile
legend(600,0.4,c("M1 xmap M2","M2 xmap M1"),lty=c(1,1),col=c("red","blue"))
abline(h=cor(dac[,'M1'],dac[,'M2']),lty=3)

```

Supplementary information 3: Univariate, multivariate and multi-view embbedings

In this demonstration, we want to forecast dynamics of Consumer1 (C1). 

Time series are generated according to a 5-species model (Resource, Consumer1, Consumer2, Predator1, Predator2) following Deyle et al. (2016). Note that the model is started with a burn-in period to ensure the dynamics relax to attractor manifold (see Deyle et al. 2016).

```{r}
## Load package and data
library(rEDM)
d <- read.csv("ESM5_Data_5spModel.csv")

```
Information (history) encoded in the dynamics of C1 is used to forecast the dynamics of C1.

```{r}
# Please reduce the number of data points if the calculation needs long time
data_used <- 1:1000

# Specify the length of time series to be used to reconstruct state space (Library length)
lib_point <- c(1,floor(max(data_used)/2))

# Specify which points will be predicted based on the reconstructed state space
pred_point <- c(floor(max(data_used)/2)+1, max(data_used))

# Time series of C1 is normalized
C1 <- as.numeric(scale(d[data_used,'C1']))

# Estimate the best embedding dimension
simp_C1_tmp <- simplex(C1, E=1:10, silent = T)
plot(simp_C1_tmp$E, simp_C1_tmp$mae, type="l", xlab="E", ylab="MAE")

# Best E = 3; lowest Mean Absolute Error
bestE_C1 <- simp_C1_tmp[which.min(simp_C1_tmp$mae),"E"]

# Perform univariate simplex projection
# We need to specify time series (C1), embedding dimension (E), library length (lib), predictee (pred) and which output we need (stats_only). If you do not want to see warning message, "silent" option should be set as "T".
simp_C1 <- simplex(C1, E=bestE_C1, lib=lib_point, pred=pred_point, stats_only = F, silent = T)
C1_pred_uni <- simp_C1$model_output[[1]]$pred
C1_obs_uni <- simp_C1$model_output[[1]]$obs
plot(C1_obs_uni, C1_pred_uni, xlab="Observed", ylab="Predicted")
abline(0,1) # add 1:1 line
```
The forecast skill (ρ) is 0.970 when we use univariate embedding (Fig. 6a in the main text).

Multivariate embedding (Deyle & Sugihara 2011, Deyle et al. 2013)

In this demonstration, we want to forecast the dynamics of C1. In the 5-species model, P1 and R are directly related to C1. Thus, we used C1, R and P1 for multivariate embedding.


```{r}
# Make multivariate embedding
Embedding <- c("C1", "R", "P1")
block <- d[,Embedding]

# Normalize data
block <- as.data.frame(apply(block, 2, function(x) (x-mean(x))/sd(x)))

# Do multivariate simplex projection using block_lnlp() function
# We need to specify time series, method (simplex or s-map), library length (lib), predictee (pred) and which output we need (stats_only).
mult_simp_C1 <-  block_lnlp(block[data_used,], method = "simplex", lib = lib_point, pred = pred_point,                            stats_only = F, silent = T)
C1_pred_mult <- mult_simp_C1$model_output[[1]]$pred
C1_obs_mult <- mult_simp_C1$model_output[[1]]$obs
plot(C1_obs_mult, C1_pred_mult, xlab="Observed", ylab="Predicted")
abline(0,1) # add 1:1 line
```
The forecast skill (ρ) is 0.987 when we use maltivariate embedding (Fig. 6b).

Multi-view embedding (Ye & Sugihara 2016)
Multi-view embedding combines multiple embeddings and leverage information of many embeddings.
```{r}
# Do multiview forecasting using multiview() function
# We need to specify time series, library length (lib), predictee (pred) and which output we need (stats_only).
multiview_C1 <- multiview(block[data_used,], lib = lib_point, pred = pred_point, stats_only = F, silent = T)
C1_pred_multv <- multiview_C1$model_output[[1]]$pred
C1_obs_multv <- multiview_C1$model_output[[1]]$obs
plot(C1_obs_multv, C1_pred_multv, xlab="Observed", ylab="Predicted")
abline(0,1) # add 1:1 line

```
The forecast skill (ρ) is 0.989 when we use multiview embedding (Fig, 6c).

Compare univariate, multivariate, and multiview embeddings
Forecasting skill improves if we use multivariate or multiview embedding compared with univariate embedding (Fig. 6d).

```{r}
rhos <- c(simp_C1$rho, mult_simp_C1$rho, multiview_C1$rho)
names(rhos) <- c("Univariate", "Multivariate", "Multiview")

# Plot result
barplot(rhos, xlab="Methods", xpd = F, ylab=expression(paste("Forecasting skill (", rho, ")")), ylim=c(0.96, 1)); box()
```

Supplementary information 4: Tracking interaction strength using S-map

Load package and time series
In this demonstration, we use the same time series generated from the 5-species model (Resource, Consumer1, Consumer2, Predator1, Predator2) following Deyle et al. (2016).
```{r}
## Load package and data
library(rEDM) 
d <- read.csv("ESM5_Data_5spModel.csv")
```

Set parameters and do S-map

In this demonstration, we focus on the effects on Consumer1 (C1). As shown in Deyle et al. (2016), the effects of Predator2 (P2) on C1 are negligible, and thus we ignore P2 in the embedding. We use fully multivariate embedding (Deyle et al. 2016, Deyle et al. 2011) in order to investigate effects of R, C2, and P1 on C1.
```{r}
# Make multivariate embedding
Embedding <- c("R","C1","C2","P1")
block <- d[,Embedding]
# Normalize data
block <- as.data.frame(apply(block, 2, function(x) (x-mean(x))/sd(x)))

# Define the target column (C1 = column 2)
targ_col <- 2

# Please reduce the number of data points if the calculation takes long
data_used <- 1:2000

# Explore the best weighting parameter (nonlinear parameter = theta)
# Best theta is selected based on mean absolute error (MAE); We try many thetas to find the best parameter
test_theta <- block_lnlp(block[data_used,], 
method = "s-map", 
num_neighbors = 0,
theta = c(0, 1e-04, 3e-04, 0.001,0.003, 0.01, 0.03, 0.1,0.3, 0.5, 0.75, 1, 1.5,2, 3, 4, 6, 8),
target_column = targ_col,
silent = T)

# Check MAE and theta
plot(test_theta$mae~test_theta$theta, type="l", xlab="Theta", ylab="MAE")

# Best theta = 8 in this case
best_theta <- test_theta[which.min(test_theta$mae),"theta"]
# Do S-map analysis with the best theta
smap_res <-  block_lnlp(block[data_used,],
method = "s-map",
num_neighbors = 0, # we have to use any value < 1 for s-map
theta = best_theta,
target_column = targ_col,
silent = T,
save_smap_coefficients = T) # save S-map coefficients]

#### Visualize results
## Observed v.s. Predicted
smap_out <- as.data.frame(smap_res$model_output[[1]])
plot(smap_out$obs, smap_out$pred, xlab="Observed", ylab="Predicted")

## Time series of fluctuating interaction strength
smap_coef <- as.data.frame(smap_res$smap_coefficients[[1]])
colnames(smap_coef) <- c("dC1dR","dC1dC1","dC1dC2","dC1dP1","Intercept")

# Plot all partial derivatives
trange <- 1:200
quartz(width=6, height=4)
plot(smap_coef[trange,"dC1dR"],
     type="l", col="royalblue", lwd=2, xlab="time",
     ylab="Interction strength", ylim = c(-1.0, 2.5),
     main = "Fluctuating interaction strength")
lines(smap_coef[trange,"dC1dC2"], lwd=2, col="red3")
lines(smap_coef[trange,"dC1dP1"], lwd=2, col="springgreen3")
abline(a=0 ,b=0 , lty="dashed", col="black", lwd=.5)

```

Supplementary information 5: Scenario exploration

Load package and time series
In this demonstration, we use the same time series generated from the 5-species model (Resource, Consumer1, Consumer2, Predator1, Predator2) following Deyle et al. (2016).


In this demonstration, we focus on the dynamics of Consumer1 (C1). We investigate how changes in Resource (R) would induce changes in C1 using scenario exploration (Deyle et al. 2013). First, we determine the best embedding dimension of C1 using simplex projection
```{r}
## Load package and data
library(rEDM) 
d <- read.csv("ESM5_Data_5spModel.csv")

# Normalize data
std_C1 <- as.numeric(scale(d[,"C1"]))

# Determine the best embedding dimension by simplex projection
E_tested <- simplex(std_C1, E=1:10, silent=T)

# The best E is determined based on MAE
E_C1 <- E_tested[which.min(E_tested$mae),"E"]

```
Then, we generate data frame for scenario exploration by adding one dimension (i.e., R(t)) to the univariate embedding. The multivariate embedding follows:
```{r}
# Normalize data
std_R <- as.numeric(scale(d[,"R"]))

# Make time-delayed embedding
embed_C1 <- embed(std_C1, dimension = E_C1)

# Add R as an external force
block0 <- cbind(embed_C1, std_R[E_C1:length(std_R)])

```
We prepare a new "R" column that includes simulated changes in Resource (0.5*sd(R) increase or decrease in Resource). The magnitude of change is arbitrarily defined here. The users can decide the magnitude of change, depending on their own research questions.
```{r}
# Make new R (increased/decreased situation)
std_R_increase <- std_R + 0.5
std_R_decrease <- std_R - 0.5

# Make new embeddings (increased/decreased situation)
block_inc0 <- cbind(embed_C1, std_R_increase[E_C1:length(std_R)])
block_dec0 <- cbind(embed_C1, std_R_decrease[E_C1:length(std_R)])

# Combine the original and simulated time series
block_inc <- rbind(block0, rep(NaN,4), block_inc0) # NaNs were added to separate two data
block_dec <- rbind(block0, rep(NaN,4), block_dec0) # NaNs were added to separate two data
colnames(block_inc) <- colnames(block_dec) <- c("C1_t","C1_t_1","C1_t_2","R_t")

```
Do scenario exploration using simplex projection
In this demonstration, we use simplex projection to forecast the effects of changing resource (R).
```{r}
# Normal multivariate simplex projection
scenario_res <- block_lnlp(block0,
                           method = "simplex",
                           columns = 1:4, # columns used to reconstruct the state space
                           target_column = 1,
                           stats_only = F,
                           silent = T)

# "Resource increased" situation
# Attractor is reconstructed using the original time series, but the dynamics dynamics is forecasted based on the resource-increased situation
scenario_inc <- block_lnlp(block_inc,
                           lib = c(1,nrow(block0)),
                           pred = c((nrow(block0)+2),nrow(block_inc)),
                           method = "simplex",
                           columns = 1:4, # columns used to reconstruct the state space.
                           target_column = 1,
                           stats_only = F,
                           silent = T)
# "Resource decreased" situation
# Attractor is reconstructed using the original time series, but the dynamics dynamics is forecasted based on the resource-increased situation
scenario_dec <- block_lnlp(block_dec,
                           lib = c(1,nrow(block0)),
                           pred = c((nrow(block0)+2),nrow(block_dec)),
                           method = "simplex",
                           columns = 1:4, # columns used to reconstruct the state space.
                           target_column = 1,
                           stats_only = F,
                           silent = T)

# Extract model outputs
pred_nochange <- scenario_res$model_output[[1]]
pred_increase <- scenario_inc$model_output[[1]]
pred_decrease <- scenario_dec$model_output[[1]]


#### Visualize results
# Extract time window (for figure)
trange <- 1:50
plot(pred_nochange[trange,"obs"],
     type="l", col="black", lwd=2, xlab="time",
     ylab="Normalized C1 values", main="Scenario exploration")

# Add predicted values using noraml multivariate simplex projection
points(pred_nochange[trange,"pred"],bg="black",pch=21)
# Add predicted values under R increased situation
points(pred_increase[trange,"pred"],bg="red",pch=24)
# Add preicted values under R increased situation
points(pred_decrease[trange,"pred"],bg="blue",pch=25)
# Add legend
legend("topleft",c("predicted","R increased","R decreased"),
       pt.bg=c(1,2,4), pch=c(21,24,25), bty="n", cex = 0.8)


```
As can be seen in Figure 8 in the main text, increase in R does not always result in increased C1. This is because the effect of R on C1 depends additionally on the condition of other species, a phenomenon known as state-dependent behavior in dynamical systems
