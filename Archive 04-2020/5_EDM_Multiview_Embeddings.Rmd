---
title: "5_EDM_Multiview_Embeddings"
author: "Alison Iles"
date: "5/13/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(ggplot2)
library(rEDM)
library(plyr)
library(reshape)
library(stringr)
library(tidyr)
```

#Multiview Embedding
The generality of Taken’s Theorem means that in situations with multivariate time series, there
can often be many different, valid attractor reconstructions. As described in (Ye and Sugihara
2016), combining these different models can result in improved forecasts.

Multiview() operates by constructing all possible embeddings of dimension E, with
lag up to max_lag (and excluding embeddings that don’t have at least one coordinate with 0
time lag). These embeddings are ranked by forecast skill (rho) over the lib portion of the
data. The individual forecasts for the top k embeddings are then averaged together.

The multiview() function in rEDM package excludes embeddings without at least one coordinate with 0 time lag. This isn't working properly because when max-lag is set one and all variables are 0 lag, it returns that none of the embeddings are valid but they all should be. I'm going to edit my own version of the multiview function, because the number of effective spawners with zero lag will be included in all embeddings. 

#Specifications for this multiview analysis
Only performed at the whole ESU level
Use only those interactions that were found to be significantly different from zero from the multivariate CCM



```{R}
rm(list=ls()) 
load("Data/Rdata/block_data.Rdata")  
name <- "Snake River ESU"

target_vars <- c("salm.rec3_n.0", "salm.rec4_n.0", "salm.rec5_n.0", "salm.rec_n.0")

best_E_T <- matrix(NA, nrow = length(target_vars), ncol = 3) # Save the optimal embedding dimension for each target variable
          colnames(best_E_T) <- c("target","E", "theta")
          best_E_T[,1] <- t(target_vars)    
tv <- 1
for(tv in 1:length(target_vars)){ # for each target variable 

    # concatenate the time series of the different stocks together
    keys <-c(names(block_data[[1]]))
    merged_data <-setNames(do.call(mapply, c(FUN=c, lapply(block_data, `[`, keys))), keys)
    merged_data <- as.data.frame(merged_data)
     valid <-  is.finite(merged_data$salm.rec3_n.0) & is.finite(merged_data$salm.rec4_n.0) & is.finite(merged_data$salm.rec5_n.0) & is.finite(merged_data$salm.eff_n.0)
    block <- merged_data[valid,]  
    rm(keys, merged_data, valid)
    
    # list the begin and end points of each stock and the break points within stocks
    lib <- matrix(NA, nrow = length(which(diff(block$year)!=1))+1, ncol = 2)
            lib[,1] <- c(1, which(diff(block$year)!=1)+1)
            lib[,2] <- c(which(diff(block$year)!=1), nrow(block))
           #only include in the library the sections of data that are continuous for at least 20 time points. 
            minlib <- lib[,2]-lib[,1]
                  lib <- lib[minlib>20,] 
           #narrow the data block to these large library sections
                  x <- block[lib[1,1]:lib[1,2],] 
                  for (r in 2:nrow(lib)){
                  xtmp <- block[lib[r,1]:lib[r,2],]
                  x <- rbind(x,xtmp)
                  }
                  block <- x
           #recreate the library list
           lib <- matrix(NA, nrow = length(which(diff(block$year)!=1))+1, ncol = 2)
                  lib[,1] <- c(1, which(diff(block$year)!=1)+1)
                  lib[,2] <- c(which(diff(block$year)!=1), nrow(block))
              rm(x,minlib, xtmp, r)
            
    # determine the best univariate embedding dimension and theta for each target variable
    block_target <- as.matrix(cbind(block$year, block[target_vars[tv]]))
          rownames(block_target) <- NULL #remove rownames to supress error in CCM: NAs introduced by coersion
          simplex_output <- simplex(block_target, E = 1:10, silent = TRUE)
          # choose the smallest E whose rho is within 1 stdv of the maximum rho)
          best_E_T[tv,2] <-  min(simplex_output$E[simplex_output$rho>max(simplex_output$rho)-sd(simplex_output$rho)]) 
          smap_output <- s_map(block_target, lib=lib, pred=lib, E=as.numeric(best_E_T[tv,2])) 
          best_E_T[tv,3]  <- smap_output$theta[which.max(smap_output$rho)] 
  
    # determine which library variables to include from the CCM analysis    
    ccm <- readRDS("Output/Rdata/3_CCM/3_CCM_SnakeESU.RDS")
          ccm <- ccm %>% filter(library==target_vars[tv]) #The 'library' variable from the ccm analysis is the target variable here. 
          ccm <- ccm[ccm$rho_eff>(3*ccm$`95p_crit`),] #only keep variables whose CCM rho from the multivariate embedding with the effective spawners is greater than the critical value
          max_ret_year <- c(3,4,5,5) #max return year for each target variable
                  #remove offsets greater than return year 
          ccm <- ccm[ccm$offset<=max_ret_year[tv],]
          #remove effective spawners as a potential causal variable, as it will be included in all multivariate embeddings
          ccm <- ccm %>% filter(target!="salm.eff_n.0")
          #remove lagged salmon variables as they will dominate the best embeddings and we are not interested in producting great forecasting models
          ccm <- ccm %>% filter(cat!="salm")
          #remove the current MVE target variable as a potential causal variable, as it will be included in all multivariate embeddings
          ccm <- ccm %>% filter(target!=target_vars[tv])

          
# Multiview embedding - make multivariate embeddings of all possible combinations of the chosen variables from the CCM analysis. Include the target variable and the number of effective spawners in each embedding. 
          
          MVE_block <- as.matrix(cbind(block["year"], block[target_vars[tv]], block["salm.eff_n.0"], block[ccm$target]))  #The chosen predictor variables are the sames as the target variables from the CCM; Here they are the library vars
          rownames(MVE_block) <- NULL #remove rownames to supress error 
          
          max_lag <-1 #number of lags of each of the chosen_vars (set to 1 as we chose our own lags for each var)
          lagged_block <- make_block(MVE_block[, 2:NCOL(MVE_block)], max_lag = max_lag)
          
          num_vars <- length(ccm$target) #number of predictor variables
          E <- as.numeric(max(3, best_E_T[tv,2])) #embedding dimension needs to be at least 3, since we are including the variable of interest and the number of effective spawners in each embedding. 
          embeddings_list <- t(combn(num_vars * max_lag, E-2, simplify = TRUE))
          embeddings_list <- embeddings_list + 2 #to include eff-n and the target variable in all embeddings
          embeddings_list <- cbind(matrix(data=1,nrow=nrow(embeddings_list), ncol=1), matrix(data=2,nrow=nrow(embeddings_list), ncol=1), embeddings_list)
        
# make in-sample forecasts
     in_results <- block_lnlp(MVE_block, lib = lib, pred = lib, 
                              method = "simplex", 
                              columns = embeddings_list, tp=1,
                              target_column = 1, #target_vars[tv],
                              stats_only = TRUE, first_column_time = TRUE)
     saveRDS(in_results, file = paste("Output/Rdata/5_MVE/5_MVE_in_results_",target_vars[tv],".RData", sep = ""), compress = FALSE)
     
     #Choose the best embeddings for each predictor variable
     num_embeddings <- NROW(in_results)
     in_sample_ranking <- order(in_results$rho, decreasing = TRUE)  # rank embeddings by rho
     ordered_embeddings <- embeddings_list[in_sample_ranking,] # order by rho
     chosen_embeddings <- matrix(0,nrow(ordered_embeddings),1)
     for (v in (3:nrow(ccm))){ #for each predictor variable
         ordered_embed_rowindex <- which(ordered_embeddings==v, arr.ind=TRUE)[1:100,1] #ID the 100 models with the highest rho (their embedding index from the ordered list of embeddings) containing that predictor variable
         chosen_embeddings[ordered_embed_rowindex] <- 1
         }
     best_embeddings <- ordered_embeddings[chosen_embeddings==1,]
     
# Save smap coefficients
     out_results <- block_lnlp(MVE_block, lib = lib, pred = lib, 
                               method = "s-map", 
                               columns = best_embeddings, tp=1, 
                               target_column = 1,
                               theta = best_E_T[tv,3],
                               stats_only = FALSE, first_column_time = TRUE,
                               save_smap_coefficients = TRUE)
     saveRDS(out_results, file = paste("Output/Rdata/5_MVE/5_MVE_out_results_MVE_block_",target_vars[tv],".RData", sep = ""), compress = FALSE)

     save.image(file = paste("Output/Rdata/5_MVE/5_MVE_work_space_",name,"_",target_vars[tv],".RData", sep = "")) 
}

```

```{R}
#this code is for extracting info from the in results of the MVE run above
target_vars <- c("salm.rec3_n.0", "salm.rec4_n.0", "salm.rec5_n.0", "salm.rec_n.0")
mpgname <- "Snake River ESU"
tv <- 4
 for(tv in 1:length(target_vars)){ # for each target variable 
load(file = paste("Output/Rdata/5_MVE/5_MVE_work_space_",mpgname,"_",target_vars[tv],".RData", sep = "")) # load work space from the MVE run for that target variable
   
   num_embeddings <- NROW(in_results)
   in_sample_ranking <- order(in_results$rho, decreasing = TRUE)  # rank embeddings by rho
   ordered_embeddings <- embeddings_list[in_sample_ranking,] # order by rho
   rho_embeddings <- in_results$rho[in_sample_ranking]
   ordered_embeddings <- cbind(ordered_embeddings,rho_embeddings)
   embed_var_names <- cbind((1:155), colnames(lagged_block)[2:156])
   colnames(embed_var_names) <- c("code_num", "var_name")
   MVE_list <- list(ordered_embeddings, embed_var_names)
   saveRDS(MVE_list, file = paste("Output/Rdata/5_MVE/5_MVE_model_summary_",target_vars[tv],".RData", sep = ""))

 }
```



```{R} 
#this code is for extracting info from the out results of the MVE runs above
target_vars <- c("salm.rec3_n.0", "salm.rec4_n.0", "salm.rec5_n.0", "salm.rec_n.0")
mpgname <- "Snake River ESU"
tv <- 1
 for(tv in 1:length(target_vars)){ # for each target variable 
load(file = paste("Output/Rdata/5_MVE/5_MVE_work_space_",mpgname,"_",target_vars[tv],".RData", sep = "")) # load work space from the MVE run for that target variable
          
     smap_coeffs <- as.data.frame(MVE_block[,1])
     colnames(smap_coeffs) <- "year"
     k <- 1
     for (k in 1:nrow(out_results)){ #for each embedding  
         k_coeffs <- data.frame(out_results$smap_coefficients[[k]]) #extract the interaction coefficients for each variable over time
         embed_names <- colnames(lagged_block[embeddings_list[k,]+1])
         coeff_names <- sapply(embed_names,function(x) paste(k,"_", round(out_results$rho[k],3),"_", target_vars[tv], "/", x, sep = ""))
         colnames(k_coeffs) <- paste(c(coeff_names, "constant"))
         smap_coeffs <- cbind(smap_coeffs, k_coeffs[,1:ncol(embeddings_list)])
          # calculate the mean of each coeff for each year (accross the different stocks in the ESU/MPG)
         k_stock_mean_coeff <- aggregate(k_coeffs[,1:ncol(embeddings_list)], list(smap_coeffs$year), mean,na.rm = TRUE)
         if (k==1){smap_coeffs_ESU_mean <-  k_stock_mean_coeff} 
         if (k>1){smap_coeffs_ESU_mean <- cbind(smap_coeffs_ESU_mean,  k_stock_mean_coeff[,2:(ncol(embeddings_list)+1)])}
     }
     saveRDS(smap_coeffs, file = paste("Output/Rdata/5_MVE/5_MVE_coeffs_",name,"_",target_vars[tv],".RData", sep = ""))
     saveRDS(smap_coeffs_ESU_mean, file = paste("Output/Rdata/5_MVE/5_MVE_coeffs_ESU_mean_",name,"_",target_vars[tv],".RData", sep = ""))
 }

```

#S-map Coefficients
Plot interaction strengths from the top k multiview embeddings.

As described in (Deyle et al. 2016), the S-map coefficients from the appropriate multivariate embedding can be interpreted as dynamic, time-varying interaction strengths. The smap_coefficients column of the block_lnlp output is a list-column with the data.frames for the S-map coefficients in the first element of that list. The result is a data.frame with a row for each prediction and columns for each of the predictor variables plus a constant.

```{R}
rm(list=ls()) 
load("Data/Rdata/block_data.Rdata")  
  
library(ggplot2)

mpg <- c() 
  for(stk in 1:length(block_data)) { 
      mpg[stk] <- block_data[[stk]]$mpg[1]
  } 

target_vars <- c("salm.rec3_n.0", "salm.rec4_n.0", "salm.rec5_n.0", "salm.rec_n.0")

u <- 0

for(u in c(0)){ #} c(0,1,3,5)){

    if(u==0){ 
    mpgname <- "Snake River ESU"
        for(tv in 1:length(target_vars)){ # for each target variable 
        smap_coeffs_ESU_mean <- readRDS(file = paste("Output/Rdata/5_MVE/5_MVE_coeffs_ESU_mean_",mpgname,"_",target_vars[tv],".RData", sep = ""))
          if(tv==1){D <- smap_coeffs_ESU_mean}
          if(tv>1){d <- smap_coeffs_ESU_mean
          D <- cbind(D, d[,2:ncol(d)])}
        }
    
    }
    D <- D %>% pivot_longer(-Group.1, names_to = "var", values_to = "IS")  #create long data for plotting
    D$mpg <- mpgname
    D <- separate(D, var, into=c("model","var"), sep = "/")  #add columns for model number, variable
    D <- separate(D, model, into=c("model","rho","target","offset"), sep = "_")  #add columns for model number, model rho, target variable
    D$offset <- NULL
    D <- separate(D, var, into=c("causal.cat","causal.subcat","causal.offset"), sep = "\\.")  #add columns for causal variable category,  
    D$year <- D$Group.1
    D$Group.1 <- NULL

D$regionlabels <- factor(D$mpg, levels=c("Snake River ESU", "Imnaha", "Middle Fork Salmon", "Upper Salmon"), labels=c("Snake River ESU", "Imnaha MPG", "Middle Fork Salmon MPG", "Upper Salmon MPG"))

D$salmoncohortlabels <- factor(D$target, levels=c("salm.rec","salm.rec3", "salm.rec4", "salm.rec5"), labels=c("All recruits", "3 yr old recruits", "4 yr old recruits", "5 yr old recruits"))

manual_color_codes <- read.csv("Data/csv_data/CORE_CCM_figure_color_codes.csv")

varcat <- unique(D$causal.cat)
D$catlabels <- factor(D$causal.cat, levels=c("hatch", "npgo", "pdo", "upw", "csl", "ssl", "harv", "hseal", "salm", "arc", "orca", "flow" ), labels=c("Hatcheries", "NPGO", "PDO", "Upwelling", "California sea lions", "Steller sea lions", "Chinook harvest", "Harbor seals", "Chinook salmon", "Sea surface temperature", "Orca whales", "River flow"))

saveRDS(D, file = paste("Output/Rdata/5_MVE/5_MVE_coeff_data_for_plotting_",mpgname,".RData", sep = ""))

# For each variable, plot the changing coefficients over time from different mutivariate embeddings
# loop through the different chosen variables
            for(i in 1:NROW(varcat)) {  
            df <- filter(D,causal.cat==varcat[i])
            mcc <- manual_color_codes[manual_color_codes$cat==varcat[i],2:4]
            mcc <- sapply(mcc, unlist)
            rownames(mcc) <- mcc[,2]
            
            p1 <- ggplot(df, aes(x=year, y=IS)) +
              geom_line(aes(col=causal.subcat, group=model)) +    
              geom_hline(aes(yintercept=0), colour='#999999') +
              theme_bw() + 
              guides(col = guide_legend(ncol=1)) +
              labs(title= df$catlabels[1], subtitle = paste("Mean effect across stocks in", mpgname, "from all multiview embeddings", sep = " "), x="year", y="interaction coefficient") + 
              scale_color_manual(values = mcc[,1], name="Time series", breaks = mcc[,2], labels = mcc[,3])
            
            p2 <- p1 + facet_grid( ~ salmoncohortlabels) 
            
            print(p2)
            
            ggsave(filename = paste("Output/Figures/5_MVE/5_MVE_", varcat[i], "_interaction_coeff_", mpgname, ".pdf", sep = ""), plot = p2, width = 7, height = 9.5, units = "in")  # saves the last plot

              }
}
```



#Figure: MVE, observed vs predicted
```{R}
# plot of observed vs predicted for the multiview embeddings
d <- MVE$model_output[[1]]

p3 <- ggplot() +
    geom_point(data=d, aes(x=time, y=obs, color="observed")) +
    geom_point(data=d, aes(x=time, y=pred, color="predicted")) +
    labs( subtitle = "Observed 4 year old recruits vs predicted", x="time", y="4 year old recruits (normalized)", color="Data") +
    theme_bw() 

print(p3)
```


